{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sjagkoo7/numpy-pandas-matplotlib-seaborn?scriptVersionId=278938282\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"00398f0f","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-11-17T02:24:09.467124Z","iopub.status.busy":"2025-11-17T02:24:09.466772Z","iopub.status.idle":"2025-11-17T02:24:11.785951Z","shell.execute_reply":"2025-11-17T02:24:11.784671Z"},"papermill":{"duration":2.32801,"end_time":"2025-11-17T02:24:11.787602","exception":false,"start_time":"2025-11-17T02:24:09.459592","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/nifty50-stock-market-data/HDFCBANK.csv\n","/kaggle/input/nifty50-stock-market-data/GRASIM.csv\n","/kaggle/input/nifty50-stock-market-data/WIPRO.csv\n","/kaggle/input/nifty50-stock-market-data/stock_metadata.csv\n","/kaggle/input/nifty50-stock-market-data/BPCL.csv\n","/kaggle/input/nifty50-stock-market-data/INFY.csv\n","/kaggle/input/nifty50-stock-market-data/LT.csv\n","/kaggle/input/nifty50-stock-market-data/RELIANCE.csv\n","/kaggle/input/nifty50-stock-market-data/BRITANNIA.csv\n","/kaggle/input/nifty50-stock-market-data/INFRATEL.csv\n","/kaggle/input/nifty50-stock-market-data/HEROMOTOCO.csv\n","/kaggle/input/nifty50-stock-market-data/HINDUNILVR.csv\n","/kaggle/input/nifty50-stock-market-data/TATAMOTORS.csv\n","/kaggle/input/nifty50-stock-market-data/MM.csv\n","/kaggle/input/nifty50-stock-market-data/HDFC.csv\n","/kaggle/input/nifty50-stock-market-data/JSWSTEEL.csv\n","/kaggle/input/nifty50-stock-market-data/TITAN.csv\n","/kaggle/input/nifty50-stock-market-data/HINDALCO.csv\n","/kaggle/input/nifty50-stock-market-data/AXISBANK.csv\n","/kaggle/input/nifty50-stock-market-data/HCLTECH.csv\n","/kaggle/input/nifty50-stock-market-data/ADANIPORTS.csv\n","/kaggle/input/nifty50-stock-market-data/GAIL.csv\n","/kaggle/input/nifty50-stock-market-data/NIFTY50_all.csv\n","/kaggle/input/nifty50-stock-market-data/BAJAJFINSV.csv\n","/kaggle/input/nifty50-stock-market-data/BAJFINANCE.csv\n","/kaggle/input/nifty50-stock-market-data/ICICIBANK.csv\n","/kaggle/input/nifty50-stock-market-data/ZEEL.csv\n","/kaggle/input/nifty50-stock-market-data/ASIANPAINT.csv\n","/kaggle/input/nifty50-stock-market-data/IOC.csv\n","/kaggle/input/nifty50-stock-market-data/TATASTEEL.csv\n","/kaggle/input/nifty50-stock-market-data/COALINDIA.csv\n","/kaggle/input/nifty50-stock-market-data/NESTLEIND.csv\n","/kaggle/input/nifty50-stock-market-data/DRREDDY.csv\n","/kaggle/input/nifty50-stock-market-data/ONGC.csv\n","/kaggle/input/nifty50-stock-market-data/EICHERMOT.csv\n","/kaggle/input/nifty50-stock-market-data/UPL.csv\n","/kaggle/input/nifty50-stock-market-data/SUNPHARMA.csv\n","/kaggle/input/nifty50-stock-market-data/ULTRACEMCO.csv\n","/kaggle/input/nifty50-stock-market-data/CIPLA.csv\n","/kaggle/input/nifty50-stock-market-data/SHREECEM.csv\n","/kaggle/input/nifty50-stock-market-data/VEDL.csv\n","/kaggle/input/nifty50-stock-market-data/TCS.csv\n","/kaggle/input/nifty50-stock-market-data/NTPC.csv\n","/kaggle/input/nifty50-stock-market-data/MARUTI.csv\n","/kaggle/input/nifty50-stock-market-data/KOTAKBANK.csv\n","/kaggle/input/nifty50-stock-market-data/ITC.csv\n","/kaggle/input/nifty50-stock-market-data/BAJAJ-AUTO.csv\n","/kaggle/input/nifty50-stock-market-data/SBIN.csv\n","/kaggle/input/nifty50-stock-market-data/INDUSINDBK.csv\n","/kaggle/input/nifty50-stock-market-data/BHARTIARTL.csv\n","/kaggle/input/nifty50-stock-market-data/TECHM.csv\n","/kaggle/input/nifty50-stock-market-data/POWERGRID.csv\n","/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"0bb04c67","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:11.800703Z","iopub.status.busy":"2025-11-17T02:24:11.799701Z","iopub.status.idle":"2025-11-17T02:24:11.879888Z","shell.execute_reply":"2025-11-17T02:24:11.878942Z"},"papermill":{"duration":0.087843,"end_time":"2025-11-17T02:24:11.881385","exception":false,"start_time":"2025-11-17T02:24:11.793542","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n","  has_large_values = (abs_vals > 1e6).any()\n","/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n","  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n","  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Symbol</th>\n","      <th>Series</th>\n","      <th>Prev Close</th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Last</th>\n","      <th>Close</th>\n","      <th>VWAP</th>\n","      <th>Volume</th>\n","      <th>Turnover</th>\n","      <th>Trades</th>\n","      <th>Deliverable Volume</th>\n","      <th>%Deliverble</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2004-08-25</td>\n","      <td>TCS</td>\n","      <td>EQ</td>\n","      <td>850.00</td>\n","      <td>1198.7</td>\n","      <td>1198.7</td>\n","      <td>979.00</td>\n","      <td>985.00</td>\n","      <td>987.95</td>\n","      <td>1008.32</td>\n","      <td>17116372</td>\n","      <td>1.725876e+15</td>\n","      <td>NaN</td>\n","      <td>5206360</td>\n","      <td>0.3042</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2004-08-26</td>\n","      <td>TCS</td>\n","      <td>EQ</td>\n","      <td>987.95</td>\n","      <td>992.0</td>\n","      <td>997.0</td>\n","      <td>975.30</td>\n","      <td>976.85</td>\n","      <td>979.00</td>\n","      <td>985.65</td>\n","      <td>5055400</td>\n","      <td>4.982865e+14</td>\n","      <td>NaN</td>\n","      <td>1294899</td>\n","      <td>0.2561</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2004-08-27</td>\n","      <td>TCS</td>\n","      <td>EQ</td>\n","      <td>979.00</td>\n","      <td>982.4</td>\n","      <td>982.4</td>\n","      <td>958.55</td>\n","      <td>961.20</td>\n","      <td>962.65</td>\n","      <td>969.94</td>\n","      <td>3830750</td>\n","      <td>3.715586e+14</td>\n","      <td>NaN</td>\n","      <td>976527</td>\n","      <td>0.2549</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2004-08-30</td>\n","      <td>TCS</td>\n","      <td>EQ</td>\n","      <td>962.65</td>\n","      <td>969.9</td>\n","      <td>990.0</td>\n","      <td>965.00</td>\n","      <td>986.40</td>\n","      <td>986.75</td>\n","      <td>982.65</td>\n","      <td>3058151</td>\n","      <td>3.005106e+14</td>\n","      <td>NaN</td>\n","      <td>701664</td>\n","      <td>0.2294</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2004-08-31</td>\n","      <td>TCS</td>\n","      <td>EQ</td>\n","      <td>986.75</td>\n","      <td>986.5</td>\n","      <td>990.0</td>\n","      <td>976.00</td>\n","      <td>987.80</td>\n","      <td>988.10</td>\n","      <td>982.18</td>\n","      <td>2649332</td>\n","      <td>2.602133e+14</td>\n","      <td>NaN</td>\n","      <td>695234</td>\n","      <td>0.2624</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Date Symbol Series  Prev Close    Open    High     Low    Last  \\\n","0  2004-08-25    TCS     EQ      850.00  1198.7  1198.7  979.00  985.00   \n","1  2004-08-26    TCS     EQ      987.95   992.0   997.0  975.30  976.85   \n","2  2004-08-27    TCS     EQ      979.00   982.4   982.4  958.55  961.20   \n","3  2004-08-30    TCS     EQ      962.65   969.9   990.0  965.00  986.40   \n","4  2004-08-31    TCS     EQ      986.75   986.5   990.0  976.00  987.80   \n","\n","    Close     VWAP    Volume      Turnover  Trades  Deliverable Volume  \\\n","0  987.95  1008.32  17116372  1.725876e+15     NaN             5206360   \n","1  979.00   985.65   5055400  4.982865e+14     NaN             1294899   \n","2  962.65   969.94   3830750  3.715586e+14     NaN              976527   \n","3  986.75   982.65   3058151  3.005106e+14     NaN              701664   \n","4  988.10   982.18   2649332  2.602133e+14     NaN              695234   \n","\n","   %Deliverble  \n","0       0.3042  \n","1       0.2561  \n","2       0.2549  \n","3       0.2294  \n","4       0.2624  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# just data reading\n","#data = pd.read_csv(\"/kaggle/input/factors-affecting-campus-placement/Placement_Data_Full_Class.csv\")\n","data = pd.read_csv(\"/kaggle/input/nifty50-stock-market-data/TCS.csv\")\n","data.head()"]},{"cell_type":"markdown","id":"71c0a5c4","metadata":{"papermill":{"duration":0.005089,"end_time":"2025-11-17T02:24:11.892104","exception":false,"start_time":"2025-11-17T02:24:11.887015","status":"completed"},"tags":[]},"source":["# Numpy +  Pandas"]},{"cell_type":"code","execution_count":3,"id":"a12154e5","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:11.903347Z","iopub.status.busy":"2025-11-17T02:24:11.903039Z","iopub.status.idle":"2025-11-17T02:24:11.906979Z","shell.execute_reply":"2025-11-17T02:24:11.906103Z"},"papermill":{"duration":0.011212,"end_time":"2025-11-17T02:24:11.908385","exception":false,"start_time":"2025-11-17T02:24:11.897173","status":"completed"},"tags":[]},"outputs":[],"source":["#help(np.array)\n","#help(np.arange)"]},{"cell_type":"code","execution_count":4,"id":"d16e8279","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:11.919876Z","iopub.status.busy":"2025-11-17T02:24:11.919563Z","iopub.status.idle":"2025-11-17T02:24:11.933833Z","shell.execute_reply":"2025-11-17T02:24:11.932922Z"},"papermill":{"duration":0.021838,"end_time":"2025-11-17T02:24:11.935399","exception":false,"start_time":"2025-11-17T02:24:11.913561","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to Numpy Learning .......!\n","numpy version : 1.26.4\n","\n","---------------- np.array using list -------------------\n","numpy array using list : [1 2 3 4 5]\n","numpy_list  type : <class 'numpy.ndarray'>\n","numpy_list  dimension : 1\n","\n","---------------- np.array using tuple -------------------\n","numpy array using tuple : [1. 2. 3. 4. 5.]\n","numpy_tuple  type : <class 'numpy.ndarray'>\n","numpy_tuple  dimension : 1\n","\n","---------------- 2-D array -------------------\n","2-D numpy array : \n"," [[1 2 3 4]\n"," [5 6 7 8]]\n","2-D numpy array  dimension : 2\n","\n","---------------- 3-D array -------------------\n","3-D numpy array : \n"," [[[ 1  2  3  4]\n","  [ 5  6  7  8]]\n","\n"," [[ 9  0 11 12]\n","  [14 15 16 17]]]\n","\n","---------------- Understading Indexing -------------------\n","Element on the 2nd row, 4th column in two_D_array : 8\n","Access the third element of the second array of the first array:7\n","sum of 2 , 3.0 and 4  : 9.0\n","\n","------------- Slicing [start:end:step] ----------------------------\n","accessing element from last : [5 4 3 2 1]\n","Slicing with step 2 Original : [1 2 3 4 5] Post slicing : [2 4]\n","2-D slicing :\n","[[2 3]\n"," [6 7]]\n","jumping by step 2 for row :\n","[[1]\n"," [2]]\n","jumping by step 2 for row and column :\n","arr[[1 3]\n"," [2 4]]\n","accessing element in reverse in 2-D numpy array:\n","[[11 12 13 14]]\n","\n","------------------- Broadcasting -----------------------------\n","Broadcasting (4, 4) and (4, 1) :\n"," [[ 1  2  3  4]\n"," [10 12 14 16]\n"," [30 33 36 39]\n"," [84 88 92 92]]\n"]}],"source":["def numpy_explore_part1():\n","    '''\n","    NumPy was created in 2005 by Travis Oliphant. NumPy aims to provide an array object that is up to 50x faster than traditional Python lists. \n","    NumPy arrays are stored at one continuous place in memory unlike lists, so processes can access and manipulate them very efficiently.\n","    This behavior is called locality of reference in computer science. It also has functions for working in domain of linear algebra, fourier transform, and matrices.\")\n","    '''\n","    print(\"Welcome to Numpy Learning .......!\")\n","    print(f\"numpy version : {np.__version__}\")\n","    \n","    # ---------------------- np.array --------------------------------\n","    print(\"\\n---------------- np.array using list -------------------\")\n","    numpy_list = np.array([1,2,3,4,5]) \n","    print(f\"numpy array using list : {numpy_list}\")\n","    print(f\"numpy_list  type : {type(numpy_list)}\")\n","    print(f\"numpy_list  dimension : {numpy_list.ndim}\")\n","\n","    print(\"\\n---------------- np.array using tuple -------------------\")\n","    numpy_tuple = np.array((1,2,3,4,5),dtype = float)\n","    print(f\"numpy array using tuple : {numpy_tuple}\")\n","    print(f\"numpy_tuple  type : {type(numpy_tuple)}\")\n","    print(f\"numpy_tuple  dimension : {numpy_tuple.ndim}\")\n","    \n","    print(\"\\n---------------- 2-D array -------------------\")\n","    two_D_array = np.array([[1,2,3,4],[5,6,7,8]])\n","    print(f\"2-D numpy array : \\n {two_D_array}\")\n","    print(f\"2-D numpy array  dimension : {two_D_array.ndim}\")\n","\n","    print(\"\\n---------------- 3-D array -------------------\")\n","    three_D_array =np.array([[[1,2,3,4],[5,6,7,8]] ,[[9,0,11,12],[14,15,16,17]]])\n","    print(f\"3-D numpy array : \\n {three_D_array}\")\n","    \n","    print(\"\\n---------------- Understading Indexing -------------------\")\n","    print(f\"Element on the 2nd row, 4th column in two_D_array : {two_D_array[1,3]}\")\n","    print(f\"Access the third element of the second array of the first array:{three_D_array[0,1,2]}\")\n","    print(f\"sum of {numpy_list[1]} , {numpy_tuple[2]} and {two_D_array[0][3]}  : {numpy_list[1]+ numpy_tuple[2]+two_D_array[0][3]}\")\n","    \n","\n","    print(\"\\n------------- Slicing [start:end:step] ----------------------------\")\n","    print(f\"accessing element from last : {numpy_list[::-1]}\")\n","    print(f\"Slicing with step 2 Original : {numpy_list} Post slicing : {numpy_list[1:4:2]}\")\n","    print(f\"2-D slicing :\\n{ two_D_array[0:2, 1:3]}\")\n","    \n","    arr = np.array([[1,2,3,4],[8,9,10,11],[2,3,4,5],[11,12,13,14]])\n","    print(f\"jumping by step 2 for row :\\n{arr[:3:2,0:1]}\")\n","    print(f\"jumping by step 2 for row and column :\\narr{arr[:3:2,0:3:2]}\")\n","    print(f\"accessing element in reverse in 2-D numpy array:\\n{arr[-1:,:]}\")\n","\n","    print(\"\\n------------------- Broadcasting -----------------------------\")\n","    array_broad1 = np.array([[1,2,3,4],[5,6,7,8],[10,11,12,13],[21,22,23,23]])\n","    array_broad2 = np.array([[1],[2],[3],[4]])\n","    result = array_broad1*array_broad2\n","    print(f\"Broadcasting {array_broad1.shape} and {array_broad2.shape} :\\n {result}\")\n","    \n","    return None\n","\n","#program execution starts from here\n","if __name__ ==  \"__main__\":\n","    numpy_explore_part1()"]},{"cell_type":"code","execution_count":5,"id":"ef1ff89d","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:11.947442Z","iopub.status.busy":"2025-11-17T02:24:11.947177Z","iopub.status.idle":"2025-11-17T02:24:11.958272Z","shell.execute_reply":"2025-11-17T02:24:11.957354Z"},"papermill":{"duration":0.018454,"end_time":"2025-11-17T02:24:11.959543","exception":false,"start_time":"2025-11-17T02:24:11.941089","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["original array after view : [ 1. 20.  3.  4.] and view array : [ 1. 20.  3.  4.]\n","\n","creating 5-D numpy array: [[[[[1. 2. 3. 4. 5.]]]]] and dimension of array :(1, 1, 1, 1, 5)\n","creating 5-D numpy array: [[[[[1. 2. 3. 4.]]]]] and dimension of array :(1, 1, 1, 1, 4)\n","convert 1-D numpy array in 2-D numpy array :\n","[[ 1  2  3  4]\n"," [ 5  6  7  8]\n"," [ 9 10 11 12]]\n","connvert 1-D numpy array to 3-D numpy array:\n","[[[ 1  2]\n","  [ 3  4]\n","  [ 5  6]]\n","\n"," [[ 7  8]\n","  [ 9 10]\n","  [11 12]]]\n","There is error in reshape please check \n","\n","Creating 3x3 identity Matrix :\n","[[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n","\n","------------- np.arange([start,] stop[, step], dtype=None) ----------------------------\n","[ 1  7  9 14]\n","[[11  2  3  4]\n"," [ 5  6 17  8]\n"," [19 10 11 12]\n"," [13 24 15 16]]\n"]}],"source":["def numpy_explore_part2():\n","    '''\n","    copy vs view : copy refer as new object , any change in copied numpy won't effect on original numpy array. \n","    However, view will affect the original numpy.\n","    '''\n","    numpy_array = np.array([1,2,3,4],dtype = float)\n","    view_numpy_array = numpy_array.view()\n","    view_numpy_array[1] = 20\n","    print(f'original array after view : {numpy_array} and view array : {view_numpy_array}')\n","\n","    '''\n","    shape vs reshape : shape to check the dimension where reshpae is reshape the numpy array.\n","    '''\n","    shape_numpy = np.array ([1,2,3,4,5],dtype  = float , ndmin=5)\n","    print(f\"\\ncreating 5-D numpy array: {shape_numpy} and dimension of array :{shape_numpy.shape}\")\n","    shape_numpy_1 = np.array ([1,2,3,4],dtype  = float , ndmin=5)\n","    print(f\"creating 5-D numpy array: {shape_numpy_1} and dimension of array :{shape_numpy_1.shape}\")\n","    \n","    try :\n","        single_array = np.array([1,2,3,4,5,6,7,8,9,10,11,12])\n","        print(f\"convert 1-D numpy array in 2-D numpy array :\\n{single_array.reshape(3,4)}\")\n","        print(f\"connvert 1-D numpy array to 3-D numpy array:\\n{single_array.reshape(2,3,2)}\")\n","        print(f\"convert 1-D numpy array in 2-D numpy array shape is wrong :\\n{single_array.reshape(3,5)}\")\n","        #print(f\"convert 1-D numpy array in 2-D numpy array :\\n{single_array.reshape(3,a)}\")\n","    except ValueError: \n","        print(\"There is error in reshape please check \")\n","    except Exception as e:\n","        print(e)\n","\n","    '''Creating Identity Matrix'''\n","    print(f\"\\nCreating 3x3 identity Matrix :\\n{np.eye(3)}\")\n","\n","    '''np.arange([start,] stop[, step], dtype=None)'''\n","    print(\"\\n------------- np.arange([start,] stop[, step], dtype=None) ----------------------------\")\n","    array1 = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n","    array2 = np.array([0,2,0,1]) # this will serve as column index\n","    array3 = array1[np.arange(4),array2]\n","    print(array3)\n","    array1[np.arange(4),array2]+=10\n","    print(array1)\n","    \n","    return None\n","\n","\n","if __name__ ==\"__main__\":\n","    numpy_explore_part2()"]},{"cell_type":"code","execution_count":6,"id":"286c98f2","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:11.971889Z","iopub.status.busy":"2025-11-17T02:24:11.971299Z","iopub.status.idle":"2025-11-17T02:24:11.980587Z","shell.execute_reply":"2025-11-17T02:24:11.979564Z"},"papermill":{"duration":0.016782,"end_time":"2025-11-17T02:24:11.982064","exception":false,"start_time":"2025-11-17T02:24:11.965282","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["for debugging mean : 81.67, std : 78.03 and meadian : 57.5 \n","for debugging lower bound : -74.39 and upper_bound : 237.73\n","debugging boolean index approach :[False False  True False False False]\n","\n","[50 60 57 55 70  5]\n"]}],"source":["# -------------------- The Outlier Cleaner --------------------\n","def clean_outliers(array: np.ndarray) -> np.ndarray:\n","    \n","    ''' Function Name: clean outliers(array: np.ndarray) -> np.ndarray\n","        Description:\n","        You are given a 1D NumPy array of integers or floats. Replace all outliers (values that are more than 2\n","        standard deviations away from the mean) with the median of the array. Return the cleaned NumPy array\n","        after replacement.\n","        Input:\n","        • array: a 1D NumPy array of integers or floats\n","        Output:\n","        • A NumPy array representing the cleaned version of the input\n","        Example:\n","        Input:\n","        array = np.array([50, 60, 250, 55, 70, 5])\n","        Output:\n","        array([50, 60, 70, 55, 70, 55]) , output of third index may not be 70''' \n","    \n","    # Calculate mean, standard deviation, and median\n","    mean = round(np.mean(array),2)\n","    std = round(np.std(array),2)\n","    median = round(np.median(array),2)\n","    print(f\"for debugging mean : {mean}, std : {std} and meadian : {median} \")\n","    \n","    # Create a copy of the array to avoid modifying the original\n","    cleaned_array = array.copy()\n","    \n","    # Find outliers (values more than 2 standard deviations from mean) and replace them with the median\n","    lower_bound = round(mean - 2 * std,2)\n","    upper_bound = round(mean + 2 * std,2)\n","    print(f\"for debugging lower bound : {lower_bound} and upper_bound : {upper_bound}\")\n","    #approach 1 :\n","    # new_list = [i if i<upper_bound else median for i in array ]\n","    # return np.array(new_list,dtype = int)\n","    \n","    #approach 2 : using boolean index approach\n","    outlier_element = (cleaned_array < lower_bound) | (cleaned_array > upper_bound)\n","    cleaned_array[outlier_element]= median\n","    print(f\"debugging boolean index approach :{outlier_element}\\n\")\n","    return cleaned_array\n","    \n","\n","if __name__ ==\"__main__\":\n","    array = np.array([50, 60, 250, 55, 70, 5]) \n","    print(clean_outliers(array))"]},{"cell_type":"code","execution_count":7,"id":"7409574e","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:11.993792Z","iopub.status.busy":"2025-11-17T02:24:11.993532Z","iopub.status.idle":"2025-11-17T02:24:11.999801Z","shell.execute_reply":"2025-11-17T02:24:11.998906Z"},"papermill":{"duration":0.013689,"end_time":"2025-11-17T02:24:12.001201","exception":false,"start_time":"2025-11-17T02:24:11.987512","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["passed image :\n"," [[10 20 30 40]\n"," [15 25 35 45]\n"," [20 30 40 50]\n"," [25 35 45 55]]\n"]}],"source":["def normalize_image(image: np.ndarray) -> float:\n","    '''The Image Normalizer\n","    Function Name: normalize image(image: np.ndarray) -> float\n","    \n","    Description:\n","    Given a 16×16 NumPy array of random integers between 0 and 255, normalize each non-overlapping\n","    4×4 block by subtracting its block mean. After normalization, compute and return the overall standard\n","    deviation of the entire normalized array.\n","    \n","    Clarification:\n","    Each 4×4 block is treated independently. Within each block:\n","    normalized block = block − mean(block)\n","    \n","    After performing this operation for all blocks, you have one combined 16×16 array of normalized values.\n","    Then compute the standard deviation of all 256 normalized values together.\n","    \n","    Worked Example:\n","    Block =\n","    [[10 20 30 40\n","    15 25 35 45\n","    20 30 40 50\n","    25 35 45 55]] ⇒ Mean = 32.5\n","    \n","    Subtract the mean:\n","    [[−22.5 −12.5 −2.5 7.5\n","    −17.5 −7.5 2.5 12.5\n","    −12.5 −2.5 7.5 17.5\n","    −7.5 2.5 12.5 22.5]]\n","    \n","    Then compute the standard deviation across the full 16×16 normalized image:\n","    SD = √( (1 / 256) * Σ (xi²) ),  where i = 1 to 256\n","    \n","    Input:\n","    • image: 2D NumPy array of shape (16, 16)\n","    Output:\n","    • A single float — the standard deviation of the final normalized image'''\n","    print(f\"passed image :\\n {image}\")\n","    return None\n","\n","if __name__ == \"__main__\":\n","    image = np.array([[10,20,30,40],[15,25,35,45],[20,30,40,50],[25,35,45,55]])\n","    normalize_image(image)"]},{"cell_type":"code","execution_count":8,"id":"619f8754","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.013134Z","iopub.status.busy":"2025-11-17T02:24:12.012442Z","iopub.status.idle":"2025-11-17T02:24:12.023133Z","shell.execute_reply":"2025-11-17T02:24:12.022228Z"},"papermill":{"duration":0.017717,"end_time":"2025-11-17T02:24:12.024376","exception":false,"start_time":"2025-11-17T02:24:12.006659","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Average of pairwsie distance : 2.828\n"]}],"source":["# -------- average pairwise Euclidean distance ----------------------\n","def pairwise_distance(A: np.ndarray, B: np.ndarray) -> float:\n","    \n","    '''\n","    Compute average pairwise Euclidean distance between points in A and B.\n","    \n","    Function Name: pairwise distance(A: np.ndarray, B: np.ndarray) -> float\n","    \n","    Description:\n","    You are given two 2D NumPy arrays, A and B, representing two sets of points in 2D space. Compute\n","    the Euclidean distance between every pair of points (i,j) where i is from A and j is from B. Each pair\n","    (i,j) is considered only once — symmetric duplicates are not counted again. Return the average of all\n","    unique pairwise distances.\n","    Mathematical Expression:\n","    d(i,j) =sqrt((A i [0] − B j [0])^2 + (A i [1] − B j [1])^2)\n","    Then compute the mean over all unique (i,j) pairs.\n","    Input:\n","    • A: NumPy array of shape (M, 2)\n","    • B: NumPy array of shape (N, 2)\n","    \n","    Output:\n","    • A single float — the average of all unique pairwise Euclidean distances\n","    Example:\n","    A = np.array([[0, 0], [1, 1]])\n","    B = np.array([[2, 2], [3, 3]])\n","    # Distances: sqrt((0-2)ˆ2+(0-2)ˆ2), sqrt((0-3)ˆ2+(0-3)ˆ2),\n","    # sqrt((1-2)ˆ2+(1-2)ˆ2), sqrt((1-3)ˆ2+(1-3)ˆ2)\n","    # => [2.828, 4.243, 1.414, 2.828]\n","    # Average = 2.828\n","    '''\n","    dist = []\n","    for i in A :\n","        for j in B :\n","            Euclidean_dist = round(np.linalg.norm(j-i),3)\n","            dist.append(Euclidean_dist)\n","    avg_val = round(sum(dist)/(len(dist)),3)\n","    return avg_val\n","\n","if __name__== \"__main__\":\n","    A = np.array([[0, 0], [1, 1]])\n","    B = np.array([[2, 2], [3, 3]])\n","    print(f\"Average of pairwsie distance : {pairwise_distance(A,B)}\")"]},{"cell_type":"code","execution_count":9,"id":"9d117bb4","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.035952Z","iopub.status.busy":"2025-11-17T02:24:12.035379Z","iopub.status.idle":"2025-11-17T02:24:12.03906Z","shell.execute_reply":"2025-11-17T02:24:12.038206Z"},"papermill":{"duration":0.010761,"end_time":"2025-11-17T02:24:12.040371","exception":false,"start_time":"2025-11-17T02:24:12.02961","status":"completed"},"tags":[]},"outputs":[],"source":["#help(pd.DataFrame)\n","#a=[1,2,3,4]\n","# same output\n","#print(a[:])\n","#print(a[::])"]},{"cell_type":"code","execution_count":10,"id":"34a97958","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.052013Z","iopub.status.busy":"2025-11-17T02:24:12.051704Z","iopub.status.idle":"2025-11-17T02:24:12.093879Z","shell.execute_reply":"2025-11-17T02:24:12.092744Z"},"papermill":{"duration":0.049806,"end_time":"2025-11-17T02:24:12.095436","exception":false,"start_time":"2025-11-17T02:24:12.04563","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Welcome to Pandas Learning .......!\n","pandas version : 2.2.3\n","\n","Pandas Series :\n","0    3.5\n","1    7.2\n","2    5.0\n","dtype: float64\n","\n","Pandas Series with custom index:\n","x    3.5\n","y    7.2\n","z    5.0\n","dtype: float64\n","\n","Pandas Series using dictionary :\n","Sub1      Math\n","sub2    Python\n","sub3       TSA\n","dtype: object\n","\n","Panas Series using custom filter from dictionary :\n","Sub1      Math\n","sub2    Python\n","dtype: object\n","\n","student_details dataframe :\n","              Name     Course     College  Year  Exam Score\n","S1  Amardeep Kumar  M.TECH AI  IIT Madras  2025         200\n","S2        PP Singh       P.HD  IIT Kanpur  2024         300\n","S3       GG Gandhi        MBA  IIT Mumbai  2023         400\n","S4        TT Singh     B.TECH     IIT Goa  2021         500\n","\n","person_details dataframe :\n","      Name  Marks     City\n","s1    Asha     85  Chennai\n","s2    Bala     90     Pune\n","s3  Chetan     78    Delhi\n","s4   Divya     92  Chennai\n","\n","using loc :\n","    Name  Marks\n","s1  Asha     85\n","\n","using loc with slicing :\n","      Name  Marks     City\n","s1    Asha     85  Chennai\n","s2    Bala     90     Pune\n","s3  Chetan     78    Delhi\n","\n","reversing dataframe using loc:\n","       City  Marks    Name\n","s4  Chennai     92   Divya\n","s3    Delhi     78  Chetan\n","s2     Pune     90    Bala\n","s1  Chennai     85    Asha\n","\n","applying filter using loc :\n","     Name  Marks\n","s1   Asha     85\n","s2   Bala     90\n","s4  Divya     92\n","\n"," using loc with conidtions :\n","     Name  Marks     City\n","s1   Asha     85  Chennai\n","s4  Divya     92  Chennai\n","\n","applying multiple connditions(lambda) using loc:\n","      Name  Marks\n","s4  Divya     92\n","\n"," Workig with iloc:\n","    Name  Marks\n","s1  Asha     85\n","s2  Bala     90\n","Working with query:\n","    Name  Marks\n","s2  Bala     90\n"]}],"source":["def pandas_explore_part1():\n","    '''\n","    Pandas was created by Wes McKinney in 2008\n","    '''\n","    \n","    print(\"Welcome to Pandas Learning .......!\")\n","    print(f\"pandas version : {pd.__version__}\\n\")\n","\n","    # ---------------------- pd.series --------------------------------\n","    print(f\"Pandas Series :\\n{pd.Series([3.5,7.2,5.0])}\")\n","    \n","    print(f\"\\nPandas Series with custom index:\\n{pd.Series([3.5,7.2,5.0],index=['x','y','z'])}\")\n","    \n","    dic_var = {'Sub1':'Math','sub2':'Python','sub3':'TSA'}\n","    print(f\"\\nPandas Series using dictionary :\\n{pd.Series(dic_var)}\")\n","    \n","    print(f\"\\nPanas Series using custom filter from dictionary :\\n{pd.Series(dic_var,index=['Sub1','sub2'])}\")\n","\n","    #----------------------- pd.DataFrame ------------------------------\n","    student_details = pd.DataFrame({'Name':['Amardeep Kumar','PP Singh','GG Gandhi','TT Singh'],\n","                 'Course' :['M.TECH AI','P.HD','MBA','B.TECH'],\n","                 'College':['IIT Madras','IIT Kanpur','IIT Mumbai','IIT Goa'],\n","                 'Year':['2025','2024','2023','2021'],\n","                 'Exam Score':[200,300,400,500]},index=['S1','S2','S3','S4'])\n","    print(f\"\\nstudent_details dataframe :\\n{student_details}\")\n","\n","    #-------loc syntax : df.loc[row_labels, column_labels] -----------------\n","    person_details = pd.DataFrame({\n","    \"Name\": [\"Asha\", \"Bala\", \"Chetan\", \"Divya\"],\n","    \"Marks\": [85, 90, 78, 92],\n","    \"City\": [\"Chennai\", \"Pune\", \"Delhi\", \"Chennai\"]}, index=[\"s1\", \"s2\", \"s3\", \"s4\"])\n","    \n","    print(f\"\\nperson_details dataframe :\\n{person_details}\")\n","    \n","    print(f\"\\nusing loc :\\n{person_details.loc[['s1'],['Name','Marks']]}\")\n","    print(f\"\\nusing loc with slicing :\\n{person_details.loc[:'s3',:]}\")\n","    print(f\"\\nreversing dataframe using loc:\\n{person_details.loc[::-1,::-1]}\")\n","    #print(person_details.loc[[:],[:]]) #gives syntax error\n","    \n","    print(f\"\\napplying filter using loc :\\n{person_details.loc[person_details['Marks']>80,['Name','Marks']]}\")\n","    print(f\"\\n using loc with conidtions :\\n{person_details.loc[(person_details['Marks']>80) & (person_details['City'] =='Chennai') ,['Name','Marks','City']]}\")\n","            # applying multiple connditions(lambda) using loc\n","    Result = person_details.loc[lambda x:(x['Marks']>85) & (x['City']=='Chennai'),['Name','Marks']]\n","    print(f\"\\napplying multiple connditions(lambda) using loc:\\n {Result}\")\n","\n","    #------- iloc syntax : df.iloc[row_positions, column_positions] ----------------\n","    print(f\"\\n Workig with iloc:\\n{person_details.iloc[:2,:2]}\")\n","\n","    #-------  query syntax : df.query()--------------------------------------------\n","    cutoff = 90\n","    print('Working with query:')\n","    print(person_details.query('Marks == @cutoff')[['Name','Marks']])\n","    #help(person_details.query)\n","    \n","    return None\n","\n","if __name__ == \"__main__\":\n","    pandas_explore_part1()"]},{"cell_type":"code","execution_count":11,"id":"bc3ccbb8","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.10748Z","iopub.status.busy":"2025-11-17T02:24:12.107196Z","iopub.status.idle":"2025-11-17T02:24:12.123731Z","shell.execute_reply":"2025-11-17T02:24:12.122815Z"},"papermill":{"duration":0.024051,"end_time":"2025-11-17T02:24:12.125137","exception":false,"start_time":"2025-11-17T02:24:12.101086","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["broadcasting ... :\n","     Name  Marks     City\n","0    Asha     85  Chennai\n","1    Bala     40     Pune\n","2  Chetan     80    Delhi\n","3   Divya     92    Vizag\n","4     Jay     53   Mumbai\n","broadcasting increasing marks ... :\n","     Name  Marks     City\n","0    Asha     85  Chennai\n","1    Bala     45     Pune\n","2  Chetan     80    Delhi\n","3   Divya     92    Vizag\n","4     Jay     58   Mumbai\n","broadcasting decreasing marks ... :\n","     Name  Marks     City\n","0    Asha     85  Chennai\n","1    Bala     45     Pune\n","2  Chetan     80    Delhi\n","3   Divya     82    Vizag\n","4     Jay     58   Mumbai\n","Broadcasting in Pandas Adding new columns :\n","     Name  Marks     City Grade\n","0    Asha     85  Chennai     B\n","1    Bala     45     Pune     C\n","2  Chetan     80    Delhi     B\n","3   Divya     82    Vizag     B\n","4     Jay     58   Mumbai     C\n"]}],"source":["def pandas_explore_part2():\n","    student_score = pd.DataFrame({\n","    \"Name\": [\"Asha\", \"Bala\", \"Chetan\", \"Divya\", \"Jay\"],\n","    \"Marks\": [85, 40, 78, 92, 53],\n","    \"City\": [\"Chennai\", \"Pune\", \"Delhi\", \"Vizag\", \"Mumbai\"]\n","    })\n","    student_score.loc[student_score['City']=='Delhi','Marks'] = 80\n","    print(f\"broadcasting ... :\\n{student_score}\")\n","\n","    student_score.loc[student_score['Marks']<60,'Marks']+=5\n","    print(f\"broadcasting increasing marks ... :\\n{student_score}\")\n","\n","    student_score.loc[lambda x: x['Marks']>90,'Marks'] -=10\n","    print(f\"broadcasting decreasing marks ... :\\n{student_score}\")\n","\n","    #------------------------------apply()------------------------------\n","    student_score['Grade'] = student_score['Marks'].apply(lambda x : \"A\" if x>85 else (\"B\" if x>75 else \"C\"))\n","    print(f\"Broadcasting in Pandas Adding new columns :\\n{student_score}\")\n","    \n","    return None\n","\n","if __name__ ==\"__main__\":\n","    pandas_explore_part2()"]},{"cell_type":"code","execution_count":12,"id":"33cce022","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.137705Z","iopub.status.busy":"2025-11-17T02:24:12.136746Z","iopub.status.idle":"2025-11-17T02:24:12.149468Z","shell.execute_reply":"2025-11-17T02:24:12.148504Z"},"papermill":{"duration":0.020154,"end_time":"2025-11-17T02:24:12.150786","exception":false,"start_time":"2025-11-17T02:24:12.130632","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["   OrderID  OrderDate   Product     Category  Price  Quantity\n","0      101 2025-10-01    Laptop  Electronics   1200         2\n","1      102 2025-10-01     Mouse  Peripherals     25         5\n","2      103 2025-10-02  Keyboard  Peripherals     75         3\n","3      104 2025-10-02    Laptop  Electronics   1250         1\n","4      105 2025-10-03   Monitor  Electronics    300         2\n","Index(['OrderID', 'OrderDate', 'Product', 'Category', 'Price', 'Quantity'], dtype='object')\n"]}],"source":["'''Use the following DataFrame as an example to understand the schema for upcoming questions. The actual DataFrame used during testing will have the same structure.'''\n","\n","data = {\n","    'OrderID': [101, 102, 103, 104, 105, 106, 107, 108],\n","    'OrderDate': ['2025-10-01', '2025-10-01', '2025-10-02',\n","                  '2025-10-02', '2025-10-03', '2025-10-04',\n","                  '2025-10-04', '2025-10-05'],\n","    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Laptop', 'Monitor',\n","                'Mouse', 'Webcam', 'Keyboard'],\n","    'Category': ['Electronics', 'Peripherals', 'Peripherals',\n","                 'Electronics', 'Electronics', 'Peripherals',\n","                 'Peripherals', 'Peripherals'],\n","    'Price': [1200, 25, 75, 1250, 300, 30, 50, 80],\n","    'Quantity': [2, 5, 3, 1, 2, 4, 1, 2]\n","}\n","\n","df = pd.DataFrame(data)\n","df['OrderDate'] = pd.to_datetime(df['OrderDate'])\n","print(df.head())\n","print(df.columns)"]},{"cell_type":"code","execution_count":13,"id":"d313d14b","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.163093Z","iopub.status.busy":"2025-11-17T02:24:12.162774Z","iopub.status.idle":"2025-11-17T02:24:12.1734Z","shell.execute_reply":"2025-11-17T02:24:12.172578Z"},"papermill":{"duration":0.018263,"end_time":"2025-11-17T02:24:12.174787","exception":false,"start_time":"2025-11-17T02:24:12.156524","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>OrderID</th>\n","      <th>OrderDate</th>\n","      <th>Product</th>\n","      <th>Category</th>\n","      <th>Price</th>\n","      <th>Quantity</th>\n","      <th>Revenue</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>2025-10-01</td>\n","      <td>Laptop</td>\n","      <td>Electronics</td>\n","      <td>1200</td>\n","      <td>2</td>\n","      <td>2400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>2025-10-01</td>\n","      <td>Mouse</td>\n","      <td>Peripherals</td>\n","      <td>25</td>\n","      <td>5</td>\n","      <td>125</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>2025-10-02</td>\n","      <td>Keyboard</td>\n","      <td>Peripherals</td>\n","      <td>75</td>\n","      <td>3</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>104</td>\n","      <td>2025-10-02</td>\n","      <td>Laptop</td>\n","      <td>Electronics</td>\n","      <td>1250</td>\n","      <td>1</td>\n","      <td>1250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>105</td>\n","      <td>2025-10-03</td>\n","      <td>Monitor</td>\n","      <td>Electronics</td>\n","      <td>300</td>\n","      <td>2</td>\n","      <td>600</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>106</td>\n","      <td>2025-10-04</td>\n","      <td>Mouse</td>\n","      <td>Peripherals</td>\n","      <td>30</td>\n","      <td>4</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>107</td>\n","      <td>2025-10-04</td>\n","      <td>Webcam</td>\n","      <td>Peripherals</td>\n","      <td>50</td>\n","      <td>1</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>108</td>\n","      <td>2025-10-05</td>\n","      <td>Keyboard</td>\n","      <td>Peripherals</td>\n","      <td>80</td>\n","      <td>2</td>\n","      <td>160</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   OrderID  OrderDate   Product     Category  Price  Quantity  Revenue\n","0      101 2025-10-01    Laptop  Electronics   1200         2     2400\n","1      102 2025-10-01     Mouse  Peripherals     25         5      125\n","2      103 2025-10-02  Keyboard  Peripherals     75         3      225\n","3      104 2025-10-02    Laptop  Electronics   1250         1     1250\n","4      105 2025-10-03   Monitor  Electronics    300         2      600\n","5      106 2025-10-04     Mouse  Peripherals     30         4      120\n","6      107 2025-10-04    Webcam  Peripherals     50         1       50\n","7      108 2025-10-05  Keyboard  Peripherals     80         2      160"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df_experiment = df.copy()\n","df_experiment['Revenue'] = df_experiment['Price']*df_experiment['Quantity']\n","df_experiment"]},{"cell_type":"code","execution_count":14,"id":"803222f4","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.189342Z","iopub.status.busy":"2025-11-17T02:24:12.188448Z","iopub.status.idle":"2025-11-17T02:24:12.20913Z","shell.execute_reply":"2025-11-17T02:24:12.208194Z"},"papermill":{"duration":0.029347,"end_time":"2025-11-17T02:24:12.210453","exception":false,"start_time":"2025-11-17T02:24:12.181106","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["           Revenue                 Product\n","               min   max    mean       max\n","OrderDate                                 \n","2025-10-01     125  2400  1262.5     Mouse\n","2025-10-02     225  1250   737.5    Laptop\n","2025-10-03     600   600   600.0   Monitor\n","2025-10-04      50   120    85.0    Webcam\n","2025-10-05     160   160   160.0  Keyboard\n"]}],"source":["try :\n","    print(df_experiment.groupby('OrderDate').agg({'Revenue':['min','max','mean'],'Product':['max']}))\n","except Exception as e:\n","    print(e)"]},{"cell_type":"code","execution_count":15,"id":"86ec87b5","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.223956Z","iopub.status.busy":"2025-11-17T02:24:12.22315Z","iopub.status.idle":"2025-11-17T02:24:12.243203Z","shell.execute_reply":"2025-11-17T02:24:12.242222Z"},"papermill":{"duration":0.028168,"end_time":"2025-11-17T02:24:12.244573","exception":false,"start_time":"2025-11-17T02:24:12.216405","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Upadted Data Frame with Revenue Column :\n","    OrderID  OrderDate   Product     Category  Price  Quantity  Revenue\n","0      101 2025-10-01    Laptop  Electronics   1200         2     2400\n","1      102 2025-10-01     Mouse  Peripherals     25         5      125\n","2      103 2025-10-02  Keyboard  Peripherals     75         3      225\n","3      104 2025-10-02    Laptop  Electronics   1250         1     1250\n","4      105 2025-10-03   Monitor  Electronics    300         2      600\n","5      106 2025-10-04     Mouse  Peripherals     30         4      120\n","6      107 2025-10-04    Webcam  Peripherals     50         1       50\n","7      108 2025-10-05  Keyboard  Peripherals     80         2      160\n","\n","list of columns :['OrderID', 'OrderDate', 'Product', 'Category', 'Price', 'Quantity', 'Revenue']\n","['Laptop', 'Laptop', 'Monitor', 'Mouse', 'Keyboard']\n"]}],"source":["# -------------------- The Daily Top Product ----------------------\n","def get_daily_top_product(df: pd.DataFrame) -> list:\n","    ''' Function Name: get daily top product(df: pd.DataFrame) -> list\n","    Description:\n","    For each unique OrderDate, find the product that generated the highest total revenue (Price ×\n","    3\n","    Quantity). Return a list of product names corresponding to each unique date, ordered by ascending\n","    OrderDate.\n","    \n","    Input:\n","    • df: DataFrame containing atleast thecolumns OrderDate, Product, Price, andQuantity.\n","    The OrderDate column should be of datetime dtype (or parseable to datetime).\n","    \n","    Output:\n","    • List[str]: Product names — one per unique date (dates in ascending order).\n","    \n","    Notes / Tie-breaking:\n","    If two products on the same date have exactly the same total revenue, the tie is broken deterministically\n","    by choosing the product that appears first after sorting by revenue descending and then by product name\n","    ascending.'''\n","    \n","    df1 = df.copy()\n","    df1['Revenue'] = df['Price']*df['Quantity']\n","    print(f\"Upadted Data Frame with Revenue Column :\\n {df1}\")\n","    print(f\"\\nlist of columns :{list(df1.columns)}\")\n","    \n","    idx = df1.groupby('OrderDate')['Revenue'].idxmax()\n","    top_product = df1.loc[idx,['Product']]\n","    \n","    top_product = list(top_product['Product'])\n","    return top_product\n","    \n","if __name__ == \"__main__\":\n","    print(get_daily_top_product(df))\n"]},{"cell_type":"code","execution_count":16,"id":"a38f21d5","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.257749Z","iopub.status.busy":"2025-11-17T02:24:12.257412Z","iopub.status.idle":"2025-11-17T02:24:12.290534Z","shell.execute_reply":"2025-11-17T02:24:12.289446Z"},"papermill":{"duration":0.041544,"end_time":"2025-11-17T02:24:12.292035","exception":false,"start_time":"2025-11-17T02:24:12.250491","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Data :    OrderID  OrderDate   Product     Category  Price  Quantity\n","0      101 2025-10-01   Monitor  Electronics   1200         2\n","1      101 2025-10-01     Mouse  Peripherals     25         5\n","2      103 2025-10-02  Keyboard  Peripherals     75         3\n","3      104 2025-10-02    Laptop  Electronics   1250         1\n","4      105 2025-10-03   Monitor  Electronics    300         2\n","\n","Data info:\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8 entries, 0 to 7\n","Data columns (total 6 columns):\n"," #   Column     Non-Null Count  Dtype         \n","---  ------     --------------  -----         \n"," 0   OrderID    8 non-null      int64         \n"," 1   OrderDate  8 non-null      datetime64[ns]\n"," 2   Product    8 non-null      object        \n"," 3   Category   8 non-null      object        \n"," 4   Price      8 non-null      int64         \n"," 5   Quantity   8 non-null      int64         \n","dtypes: datetime64[ns](1), int64(3), object(2)\n","memory usage: 516.0+ bytes\n","None\n","\n","Data Statistics :\n","         OrderID            OrderDate        Price  Quantity\n","count    8.00000                    8     8.000000  8.000000\n","mean   104.25000  2025-10-02 18:00:00   376.250000  2.500000\n","min    101.00000  2025-10-01 00:00:00    25.000000  1.000000\n","25%    102.50000  2025-10-01 18:00:00    45.000000  1.750000\n","50%    104.50000  2025-10-02 12:00:00    77.500000  2.000000\n","75%    105.50000  2025-10-04 00:00:00   525.000000  3.250000\n","max    108.00000  2025-10-05 00:00:00  1250.000000  5.000000\n","std      2.54951                  NaN   531.310711  1.414214\n"]}],"source":["'''Use the following DataFrame as an example to understand the schema for upcoming questions. The actual DataFrame used during testing will have the same structure.'''\n","data = {\n","    'OrderID': [101, 101, 103, 104, 105, 105, 107, 108],\n","    'OrderDate': ['2025-10-01', '2025-10-01', '2025-10-02',\n","                  '2025-10-02', '2025-10-03', '2025-10-04',\n","                  '2025-10-04', '2025-10-05'],\n","    'Product': ['Monitor', 'Mouse', 'Keyboard', 'Laptop', 'Monitor',\n","                'Mouse', 'Webcam', 'Keyboard'],\n","    'Category': ['Electronics', 'Peripherals', 'Peripherals',\n","                 'Electronics', 'Electronics', 'Peripherals',\n","                 'Peripherals', 'Peripherals'],\n","    'Price': [1200, 25, 75, 1250, 300, 30, 50, 80],\n","    'Quantity': [2, 5, 3, 1, 2, 4, 1, 2]\n","}\n","\n","df_frequent_product_pair = pd.DataFrame(data)\n","df_frequent_product_pair['OrderDate'] = pd.to_datetime(df_frequent_product_pair['OrderDate'])\n","print(f\"Data : {df_frequent_product_pair.head()}\")\n","print(\"\\nData info:\\n\")\n","print(df_frequent_product_pair.info())\n","print(f\"\\nData Statistics :\\n{df_frequent_product_pair.describe()}\")"]},{"cell_type":"code","execution_count":17,"id":"505c2809","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.306204Z","iopub.status.busy":"2025-11-17T02:24:12.305901Z","iopub.status.idle":"2025-11-17T02:24:12.321321Z","shell.execute_reply":"2025-11-17T02:24:12.320508Z"},"papermill":{"duration":0.02411,"end_time":"2025-11-17T02:24:12.322584","exception":false,"start_time":"2025-11-17T02:24:12.298474","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame with only more than one product:\n","   OrderID  Product     Category  Price  Quantity\n","0      101  Monitor  Electronics   1200         2\n","1      101    Mouse  Peripherals     25         5\n","4      105  Monitor  Electronics    300         2\n","5      105    Mouse  Peripherals     30         4\n","('Monitor', 'Mouse')\n"]}],"source":["# ---------------------  The Product Relationship Puzzle ------------------------\n","def frequent_product_pair(df: pd.DataFrame) -> tuple:\n","    \n","    '''Function Name: strongest product pair(df: pd.DataFrame) -> tuple\n","    \n","    Description:\n","    Find the pair of products that are most frequently bought together, i.e., appear in the same OrderID.\n","    Each unique order can contain multiple products, and you must identify the two products that co-occur\n","    most often across all orders.\n","    Return the names of the two products as a tuple (product1, product2). The pair should be\n","    ordered alphabetically, i.e., product1 < product2.\n","    \n","    Input:\n","    • df: Pandas DataFrame with columns OrderID,Product, Category, Price, and Quantity.\n","    \n","    Output:\n","    • Tuple[str, str] — the names of the two products most frequently co-purchased.\n","    \n","    Notes:\n","    • Each OrderID can have one or more products.\n","    • You should only consider pairs of distinct products.\n","    • If two pairs have the same frequency, choose the pair that is lexicographically smallest (alphabet-\n","    ical order). '''\n","    df_boolean = df.groupby('OrderID')['Product'].count()>=2\n","    df_series = pd.Series(df_boolean)\n","    df_grouped = df[df['OrderID'].map(df_series)]\n","    print(f\"DataFrame with only more than one product:\\n{df_grouped}\")\n","    df_grouped_product = df_grouped.groupby('Product')['Product'].count().sort_values(ascending=False)\n","    lst = list(df_grouped_product.index)\n","    lst.sort()\n","    return tuple(lst[:2])\n","\n","\n","if __name__ == \"__main__\":\n","    df1 = df_frequent_product_pair.copy()\n","    if 'OrderDate' in list(df_frequent_product_pair.columns):\n","        df1 = df1.drop('OrderDate',axis=1)\n","    else :\n","        pass\n","    #print(df1)\n","    print(frequent_product_pair(df1))"]},{"cell_type":"code","execution_count":18,"id":"ff0e06c1","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.335802Z","iopub.status.busy":"2025-11-17T02:24:12.335509Z","iopub.status.idle":"2025-11-17T02:24:12.362362Z","shell.execute_reply":"2025-11-17T02:24:12.361379Z"},"papermill":{"duration":0.034896,"end_time":"2025-11-17T02:24:12.363674","exception":false,"start_time":"2025-11-17T02:24:12.328778","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Data :\n","    OrderID  OrderDate   Product     Category  Price  Quantity\n","0      101 2025-10-01    Laptop  Electronics   1200         2\n","1      102 2025-10-01     Mouse  Peripherals     25         5\n","2      103 2025-10-02  Keyboard  Peripherals     75         3\n","3      104 2025-10-02    Laptop  Electronics   1250         1\n","4      105 2025-10-03   Monitor  Electronics    300         2\n","\n","Data info:\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8 entries, 0 to 7\n","Data columns (total 6 columns):\n"," #   Column     Non-Null Count  Dtype         \n","---  ------     --------------  -----         \n"," 0   OrderID    8 non-null      int64         \n"," 1   OrderDate  8 non-null      datetime64[ns]\n"," 2   Product    8 non-null      object        \n"," 3   Category   8 non-null      object        \n"," 4   Price      8 non-null      int64         \n"," 5   Quantity   8 non-null      int64         \n","dtypes: datetime64[ns](1), int64(3), object(2)\n","memory usage: 516.0+ bytes\n","None\n","\n","Data Statistics :\n","         OrderID            OrderDate        Price  Quantity\n","count    8.00000                    8     8.000000  8.000000\n","mean   104.50000  2025-10-02 18:00:00   376.250000  2.500000\n","min    101.00000  2025-10-01 00:00:00    25.000000  1.000000\n","25%    102.75000  2025-10-01 18:00:00    45.000000  1.750000\n","50%    104.50000  2025-10-02 12:00:00    77.500000  2.000000\n","75%    106.25000  2025-10-04 00:00:00   525.000000  3.250000\n","max    108.00000  2025-10-05 00:00:00  1250.000000  5.000000\n","std      2.44949                  NaN   531.310711  1.414214\n"]}],"source":["'''Use the following DataFrame as an example to understand the schema for upcoming questions. The actual DataFrame used during testing will have the same structure.'''\n","data = {\n","    'OrderID': [101, 102, 103, 104, 105, 106, 107, 108],\n","    'OrderDate': ['2025-10-01', '2025-10-01', '2025-10-02',\n","                  '2025-10-02', '2025-10-03', '2025-10-04',\n","                  '2025-10-04', '2025-10-05'],\n","    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Laptop', 'Monitor',\n","                'Mouse', 'Webcam', 'Keyboard'],\n","    'Category': ['Electronics', 'Peripherals', 'Peripherals',\n","                 'Electronics', 'Electronics', 'Peripherals',\n","                 'Peripherals', 'Peripherals'],\n","    'Price': [1200, 25, 75, 1250, 300, 30, 50, 80],\n","    'Quantity': [2, 5, 3, 1, 2, 4, 1, 2]\n","}\n","\n","df_most_frequent_leader = pd.DataFrame(data)\n","df_most_frequent_leader['OrderDate'] = pd.to_datetime(df_most_frequent_leader['OrderDate'])\n","print(f\"Data :\\n {df_most_frequent_leader.head()}\")\n","print(\"\\nData info:\\n\")\n","print(df_most_frequent_leader.info())\n","print(f\"\\nData Statistics :\\n{df_most_frequent_leader.describe()}\")"]},{"cell_type":"code","execution_count":19,"id":"afa038b4","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.377665Z","iopub.status.busy":"2025-11-17T02:24:12.377352Z","iopub.status.idle":"2025-11-17T02:24:12.396144Z","shell.execute_reply":"2025-11-17T02:24:12.395318Z"},"papermill":{"duration":0.02714,"end_time":"2025-11-17T02:24:12.397442","exception":false,"start_time":"2025-11-17T02:24:12.370302","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Electronics\n"]}],"source":["# -----------------------  The Dominant Category Challenge ----------------------\n","def most_frequent_leader(df: pd.DataFrame) -> str:\n","    \n","    '''Function name: most frequent leader(df: pd.DataFrame) -> str\n","    \n","    Use the following DataFrame as an example to understand the schema for this question. The actual\n","    DataFrame used during testing will have the same structure.\n","\n","    data = {\n","    ’OrderID’: [101, 102, 103, 104, 105, 106, 107, 108],\n","    ’OrderDate’: [’2025-10-01’, ’2025-10-01’, ’2025-10-02’,\n","    ’2025-10-02’, ’2025-10-03’, ’2025-10-04’,\n","    ’2025-10-04’, ’2025-10-05’],\n","    ’Product’: [’Laptop’, ’Mouse’, ’Keyboard’, ’Laptop’, ’Monitor’,\n","    ’Mouse’, ’Webcam’, ’Keyboard’],\n","    ’Category’: [’Electronics’, ’Peripherals’, ’Peripherals’,\n","    ’Electronics’, ’Electronics’, ’Peripherals’,\n","    ’Peripherals’, ’Peripherals’],\n","    ’Price’: [1200, 25, 75, 1250, 300, 30, 50, 80],\n","    ’Quantity’: [2, 5, 3, 1, 2, 4, 1, 2]\n","    }\n","    \n","    For each date, compute cumulative revenue for each category up to that date. Then determine which\n","    category leads (i.e., has the highest cumulative revenue) most frequently across all dates. Return the\n","    category name as a string.\n","    \n","    Input:\n","    • df: Pandas DataFrame with columns OrderDate, Category, Price, and Quantity.\n","    Output: String — most frequent leader in cumulative revenue.'''\n","\n","    df['Revenue'] = df['Price']*df['Quantity']\n","    df = df[['OrderDate','Category','Revenue']]\n","    df_grouped = df.groupby(['OrderDate','Category'])['Revenue'].sum().reset_index()\n","    df_grouped['Cummulative Revenue'] = df_grouped.groupby('Category')['Revenue'].cumsum()\n","    df_grouped = df_grouped.loc[df_grouped.groupby('Category')['Cummulative Revenue'].idxmax()]\n","    df_grouped = df_grouped.sort_values('Cummulative Revenue',ascending = False)\n","    return  df_grouped.iloc[0,1]\n","\n","if __name__ == \"__main__\":\n","    df1 = df_most_frequent_leader.copy()\n","    if 'OrderDate' in list(df_most_frequent_leader.columns):\n","        df1 = df1.drop(['OrderID','Product'],axis=1)\n","    else :\n","        pass\n","    #print(df1)\n","    print(most_frequent_leader(df1))"]},{"cell_type":"code","execution_count":20,"id":"a6d65516","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.411188Z","iopub.status.busy":"2025-11-17T02:24:12.410891Z","iopub.status.idle":"2025-11-17T02:24:12.42001Z","shell.execute_reply":"2025-11-17T02:24:12.419161Z"},"papermill":{"duration":0.01749,"end_time":"2025-11-17T02:24:12.421286","exception":false,"start_time":"2025-11-17T02:24:12.403796","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[(118.82, 4), (120.82, 4), (109.48, 3), (116.15, 5), (114.69, 5), (114.02, 3), (120.85, 1), (120.36, 2), (122.78, 1), (125.68, 3), (132.75, 4), (132.13, 4), (133.7, 2), (129.43, 2), (129.6, 5), (133.0, 4), (135.96, 5), (132.05, 3), (130.06, 1), (125.92, 5), (129.99, 3), (128.84, 3), (132.92, 2), (134.07, 2), (140.22, 3), (146.23, 4), (149.3, 5), (156.45, 2), (157.0, 5), (155.1, 5)]\n"]}],"source":["# ----------------------------------- The Sales Simulation -----------------------\n","def simulate_sales(sales_df: pd.DataFrame, days: int = 30) -> list :\n","    '''Functionname: simulate sales(sales df: pd.DataFrame, days: int = 30) ->\n","    list\n","    Simulate sales data for the next days (default = 30).\n","    For each day, generate:\n","    • A price = last known price + random noise from Normal(0, 5)\n","    • A quantity = random integer between 1 and 5\n","    \n","    Return a list of tuples, where each tuple represents one simulated sale: (price, quantity) for\n","    each simulated day.\n","    \n","    Input:\n","    • sales df: Pandas DataFrame with columns OrderDate, Product, Price.\n","    • days: integer (default 30) — number of simulated days.\n","    \n","    Output: List of tuples: [(price1, qty1), (price2, qty2), ...] of length days.'''\n","    if sales_df.empty:\n","        return []\n","    df_sorted = sales_df.sort_values('OrderDate')\n","    current_price = df_sorted['Price'].iloc[-1]\n","    current_price = float(current_price)\n","    simulated_sales=[]\n","    for _ in range(days):\n","        simulated_price = round(current_price + np.random.normal(0,5),2)\n","        simulated_quantity = np.random.randint(1,6)\n","        simulated_sales.append((simulated_price, simulated_quantity))\n","        current_price = simulated_price\n","    return simulated_sales\n","\n","np.random.seed(0)\n","if __name__ == \"__main__\" :\n","    data = {\n","    'OrderID': [101, 102, 103],\n","    'OrderDate': ['2025-10-01', '2025-10-02', '2025-10-03'],\n","    'Price': [100, 105, 110]}\n","    df = pd.DataFrame(data)\n","    #print(df)\n","    print(simulate_sales(df,30))"]},{"cell_type":"code","execution_count":21,"id":"b81c3a98","metadata":{"execution":{"iopub.execute_input":"2025-11-17T02:24:12.435501Z","iopub.status.busy":"2025-11-17T02:24:12.434946Z","iopub.status.idle":"2025-11-17T02:24:12.442465Z","shell.execute_reply":"2025-11-17T02:24:12.441578Z"},"papermill":{"duration":0.01635,"end_time":"2025-11-17T02:24:12.444045","exception":false,"start_time":"2025-11-17T02:24:12.427695","status":"completed"},"tags":[]},"outputs":[],"source":["# ---------------------- The Weighted Moving Average (WMA) --------------------\n","def weighted_moving_average(df: pd.DataFrame, weights: np.ndarray) -> list:\n","\n","    '''Functionname: weighted moving average(df: pd.DataFrame, weights: np.ndarray) -> list:\n","    \n","    Compute the Weighted Moving Average (WMA) of total daily revenues per category across all days.\n","    \n","    The WMA assigns more weight to recent days (e.g., with weights [0.5, 0.3, 0.2], the latest day gets 0.5).\n","    Return a list containing the WMA value for each day. For the first few days (where there are fewer\n","    than the required number of previous days), compute the WMA using the available subset of weights\n","    (normalize them so they still sum to 1).\n","    \n","    Input:\n","    • df: PandasDataFramewithcolumns[’OrderDate’, ’Category’, ’Price’, ’Quantity’].\n","    • weights: list or NumPy array of weights (most recent day has the first weight).\n","    \n","    Output: List of floats — one WMA value per day.'''\n","\n","    return None\n","\n","\n","if __name__ == \"__main__\":\n","    data1 = {'OrderDate':['2025-10-01'],'Price':[100],'Quantity':[1],'Category':['Electronics']}\n","    data2 = {'OrderDate':['2025-10-01','2025-10-02'],'Price':[50,70],'Quantity':[2,3],'Category':['A','A']}\n","    df1 = pd.DataFrame(data1)\n","    df2 = pd.DataFrame(data2)\n","    lst = [df1,df2]\n","    weights = 3\n","    # print(df1)\n","    # print('\\n')\n","    # print(df2)\n","    for df in lst :\n","        weighted_moving_average(df, weights)"]},{"cell_type":"markdown","id":"076ac3d7","metadata":{"papermill":{"duration":0.006127,"end_time":"2025-11-17T02:24:12.456905","exception":false,"start_time":"2025-11-17T02:24:12.450778","status":"completed"},"tags":[]},"source":["# Matplotlib +  Seaborn"]},{"cell_type":"markdown","id":"cfde2e7a","metadata":{"papermill":{"duration":0.005815,"end_time":"2025-11-17T02:24:12.469032","exception":false,"start_time":"2025-11-17T02:24:12.463217","status":"completed"},"tags":[]},"source":["# References :\n","- https://www.w3schools.com/python/numpy"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":596958,"sourceId":1073629,"sourceType":"datasetVersion"},{"datasetId":423609,"sourceId":2179861,"sourceType":"datasetVersion"}],"dockerImageVersionId":31153,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":8.202886,"end_time":"2025-11-17T02:24:12.994316","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-17T02:24:04.79143","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}