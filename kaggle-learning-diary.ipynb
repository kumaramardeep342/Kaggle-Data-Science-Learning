{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sjagkoo7/kaggle-learning-diary?scriptVersionId=134435153\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"72ba3f6d","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-22T03:19:50.778414Z","iopub.status.busy":"2023-06-22T03:19:50.777235Z","iopub.status.idle":"2023-06-22T03:19:50.791739Z","shell.execute_reply":"2023-06-22T03:19:50.790628Z"},"papermill":{"duration":0.025771,"end_time":"2023-06-22T03:19:50.794669","exception":false,"start_time":"2023-06-22T03:19:50.768898","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"0c99e708","metadata":{"papermill":{"duration":0.004747,"end_time":"2023-06-22T03:19:50.804753","exception":false,"start_time":"2023-06-22T03:19:50.800006","status":"completed"},"tags":[]},"source":[">  **Learning from**\n","1.  **EDA of IPL Matches_Am** notebook\n","2.  **Feature-Engineering IPL 2008 to 2020 _Am** notebook\n","3.  **Visualization IPL 2008 to 2020_Am** notebook\n","* matches['city'].replace(to_replace='Bengaluru',value='Bangalore',inplace=True) **replace Bengaluru with Banglore**\n","* win_per_season = matches.groupby('season').winner.value_counts() **grouby**\n","* win_per_season_df=pd.DataFrame(columns=['season','team','no_of_time_won'])\n","\n","     year=2008\n","     for items in win_per_season.items():\n","        if(items[0][0]==year):\n","            print(items)\n","            temp=pd.DataFrame({'season':[items[0][0]],'team':[items[0][1]],'no_of_time_won':[items[1]]})\n","            win_per_season_df=win_per_season_df.append(temp,ignore_index=True)\n","            year=year+1\n","> loc vs iloc\n","    * loc is label-based, which means that you have to specify rows and columns based on their row and column labels.\n","    * iloc is integer position-based, so you have to specify rows and columns by their integer position values (0-based integer position). \n","    * loc[row_label, column_label]\n","    * iloc[row_position, column_position]\n","    * 1.Selecting via a single value 2.Selecting via a list of values 3.Selecting a range of data via slice 4.Selecting via conditions and callable\n","    * https://towardsdatascience.com/how-to-use-loc-and-iloc-for-selecting-data-in-pandas-bd09cb4c3d79\n","* idxmax() , idxmin() , ge() --> greater than equal to"]},{"cell_type":"markdown","id":"057cc172","metadata":{"papermill":{"duration":0.004768,"end_time":"2023-06-22T03:19:50.814641","exception":false,"start_time":"2023-06-22T03:19:50.809873","status":"completed"},"tags":[]},"source":["> 4. Learning from **Estes Park Weather EDA_Am** notebook\n","* avg_50_75_diff =climate['Average temperature (°F)'].quantile(q=0.75)-climate['Average temperature (°F)'].quantile(q=0.5)\n","* print('avg_50_75_diff :', round(avg_50_75_diff,2)) -- count calculate quantile"]},{"cell_type":"markdown","id":"6accd440","metadata":{"papermill":{"duration":0.004862,"end_time":"2023-06-22T03:19:50.825105","exception":false,"start_time":"2023-06-22T03:19:50.820243","status":"completed"},"tags":[]},"source":["> 5. Learning from **Cryptocurrencies_Am** notebook\n","* A1=df.head(3).to_dict('list')\n","* list_1=list_1['Currency_Name'].to_list()\n","* set_xlabel,set_ylabel,set_title,legend,set_xticks,set_xticklabels,set_yticks,set_yticklabels"]},{"cell_type":"markdown","id":"76b4cab1","metadata":{"papermill":{"duration":0.004835,"end_time":"2023-06-22T03:19:50.835084","exception":false,"start_time":"2023-06-22T03:19:50.830249","status":"completed"},"tags":[]},"source":["> 6. Learning from **Boston House Prices_Am** notebook\n","* from sklearn import metrics\n","* from sklearn.model_selection import train_test_split\n","* X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=4)\n","> **Linear Regression**\n","* from sklearn.linear_model import LinearRegression -- Import library for Linear Regression\n","* lr=LinearRegression() -- Create a Linear regressor\n","* lr.fit(X_train,y_train) -- Train the model using the training sets\n","* y_pred=lr.predict(X_test) -- Model prediction on train data\n","> **Linear Regression model Evaluation**\n","* print('R^2:',metrics.r2_score(y_test,y_pred_test))\n","* print('Adjusted R^2 :',1-((1-metrics.r2_score(y_test,y_pred_test))*(len(y_test)-1))/(len(y_test)-len(house.columns)-1))\n","* print('MAE:',metrics.mean_absolute_error(y_test,y_pred_test))\n","* print('MSE:',metrics.mean_squared_error(y_test,y_pred_test))\n","* print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,y_pred_test)))"]},{"cell_type":"markdown","id":"86b94ce4","metadata":{"papermill":{"duration":0.004719,"end_time":"2023-06-22T03:19:50.845026","exception":false,"start_time":"2023-06-22T03:19:50.840307","status":"completed"},"tags":[]},"source":["> 7. Learning from **EDA of Top 500 Indian Cities Population** notebook"]},{"cell_type":"markdown","id":"9fd2052b","metadata":{"papermill":{"duration":0.004728,"end_time":"2023-06-22T03:19:50.854824","exception":false,"start_time":"2023-06-22T03:19:50.850096","status":"completed"},"tags":[]},"source":["> 8. Learning from **Data Analysis+Regression+Classification** notebook\n","* **Data Wrangling**    \n","* def transform_categorical_column(data,column_name):\n","    categories=data[column_name].value_counts().index.to_list()\n","    map_cat={k:v  for v,k in enumerate(categories)}\n","    rev_map_cat={v:k for k,v in map_cat.items()}\n","    data[column_name]=data[column_name].map(map_cat)\n","    return data,map_cat,rev_map_cat\n","*  data, map_gender, reverse_map_gender=transform_categorical_column(data, 'gender')\n","> **Classification- Decision Tree Classification**\n","* from sklearn.tree import DecisionTreeClassifier\n","* from sklearn.metrics import accuracy_score,classification_report\n","* dtree=DecisionTreeClassifier(criterion=\"entropy\")\n","* dtree.fit(X_train,y_train)\n","* y_pred=dtree.predict(X_test)\n","> **Classification model Evaluation**\n","* accuracy_score(y_test,y_pred)\n","* print(classification_report(y_test,y_pred))"]},{"cell_type":"markdown","id":"86e11b6b","metadata":{"papermill":{"duration":0.00484,"end_time":"2023-06-22T03:19:50.864813","exception":false,"start_time":"2023-06-22T03:19:50.859973","status":"completed"},"tags":[]},"source":["> 9. Learning from **Supermarket Sales EDA** notebook\n","* **Pie chart using Matplotlib**\n","* fig=plt.figure(figsize=(10,5))\n","* ax=fig.add_subplot(111)\n","* ax.set(title='Product line')\n","* plt.pie(x=sales['Product line'].value_counts(),autopct='%.1f%%',labels=sales['Product line'].value_counts().index)\n","* plt.show()\n","> Datetime\n","* sales['Date2']=pd.to_datetime(sales['Date1'])\n","* sales['Day']=sales.Date2.dt.day\n","* sales['Month']=sales.Date2.dt.month\n","* sales['Year']=sales.Date2.dt.year\n","* sales['Weekday']=sales.Date2.dt.dayofweek\n","* sales['Hour']=sales.Time1.dt.hour"]},{"cell_type":"markdown","id":"1c6aebb5","metadata":{"papermill":{"duration":0.004723,"end_time":"2023-06-22T03:19:50.874591","exception":false,"start_time":"2023-06-22T03:19:50.869868","status":"completed"},"tags":[]},"source":["> 10. Learning from **heart-failure-prediction_Am** notebok\n","* plt.subplot(x,y,z)\n","        x - row\n","        y - column\n","        z - plot number\n","        total graph will be = x * y and z will be squence number of graph\n","* plt.tight_layout()\n","* For not Tree based Machine Learning Algorithms the best way to go will be to use One-Hot Encoding \n","* For Tree based Machine Learning Algorithms the best way to go is with Label Encoding \n","* Using Decision Tree based Algorithm does not require feature scaling, and works great also in presence of categorical columns without ONE_HOT Encoding"]},{"cell_type":"markdown","id":"96b48857","metadata":{"papermill":{"duration":0.004704,"end_time":"2023-06-22T03:19:50.884464","exception":false,"start_time":"2023-06-22T03:19:50.87976","status":"completed"},"tags":[]},"source":["> 11. Learning from **Apps Installs EDA** notebook\n","* https://www.programiz.com/python-programming/datetime/strptime\n","* https://www.programiz.com/python-programming/datetime/strftime\n","* https://jovian.com/sanketchavan5595/exploratory-data-analysis-on-google-playstore-apps\n","> **Convert 10,00000+ object to 1000000 number**\n","* data['Installs']=data['Installs'].apply(lambda x:x.replace(',',''))\n","* data['Installs']=data['Installs'].apply(lambda x:x.replace('+',''))\n","* data['Installs']=pd.to_numeric(data['Installs'])"]},{"cell_type":"markdown","id":"ce7e3885","metadata":{"papermill":{"duration":0.004657,"end_time":"2023-06-22T03:19:50.894245","exception":false,"start_time":"2023-06-22T03:19:50.889588","status":"completed"},"tags":[]},"source":["> 12. Learning from **Policy Prediction Am** notebook\n","* import ydata_profiling\n","* tr_data.profile_report(title='Customer Report',progress_bar=False)"]},{"cell_type":"markdown","id":"e235ec06","metadata":{"papermill":{"duration":0.004692,"end_time":"2023-06-22T03:19:50.903994","exception":false,"start_time":"2023-06-22T03:19:50.899302","status":"completed"},"tags":[]},"source":["> 13. Learning from **Car Evaluation|Decision Tree,Random Forest,SVM** notebook"]},{"cell_type":"markdown","id":"26523290","metadata":{"papermill":{"duration":0.004788,"end_time":"2023-06-22T03:19:50.913798","exception":false,"start_time":"2023-06-22T03:19:50.90901","status":"completed"},"tags":[]},"source":["> 14. Learning from **Binary Classification of Machine Failures S3E17** notebook\n","* **Ensemble - Random Forest Classifier**\n","* from sklearn.ensemble import RandomForestClassifier\n","* dtree=RandomForestClassifier(n_estimators=100,criterion='entropy')\n","* dtree.fit(X_train,y_train)\n","> Label Encoding - Used with Tree Based Algorthms\n","* from sklearn.preprocessing import LabelEncoder\n","* df_tree = df.apply(LabelEncoder().fit_transform)\n","* df_tree.head()\n","> One Hot Encoding - Used with One-Hot Encoding\n","* pd.get_dummies()\n","* df_nontree=pd.get_dummies(df,columns=string_col,drop_first=False)\n","* df_nontree.head()"]},{"cell_type":"markdown","id":"0cfa7c56","metadata":{"papermill":{"duration":0.004673,"end_time":"2023-06-22T03:19:50.923525","exception":false,"start_time":"2023-06-22T03:19:50.918852","status":"completed"},"tags":[]},"source":["> **General**\n","* 40 of the Best Beginner-Friendly Kaggle Notebooks to Learn Exploratory Data Analysis (EDA) -https://medium.com/@ebrahimhaqbhatti516/40-of-the-best-beginner-friendly-kaggle-notebooks-to-learn-exploratory-data-analysis-eda-6e45760646aa"]},{"cell_type":"markdown","id":"2f2803ae","metadata":{"papermill":{"duration":0.004666,"end_time":"2023-06-22T03:19:50.933223","exception":false,"start_time":"2023-06-22T03:19:50.928557","status":"completed"},"tags":[]},"source":["> **Steps in a Machine Learning Project**\n","* Defining the Problem\n","* Obtaining the Source Data\n","* Preparing Data for Machine Learning Algorithms\n","    > *Data Preprocessing*\n","    * Handling Null Values || Data Cleaning\n","    * Feature Scaling || Feature Engineering || Feature Selection\n","    * Handling Categorical Variables || One Hot Encoding & Label Encoding\n","* Understanding Data Through Visualization\n","* Chossing an algorithm\n","* Builiding the Model\n","* Fine-tuning the Model\n","     > *Model Evaluation*\n","* Use the best model"]},{"cell_type":"markdown","id":"391cefca","metadata":{"papermill":{"duration":0.004749,"end_time":"2023-06-22T03:19:50.943112","exception":false,"start_time":"2023-06-22T03:19:50.938363","status":"completed"},"tags":[]},"source":["#### \n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":15.922024,"end_time":"2023-06-22T03:19:51.671661","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-22T03:19:35.749637","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}