{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sjagkoo7/health-of-horses-s3-ep22-xgb-lgbm-catboost?scriptVersionId=144873146\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"<div style = \"color: White; display: fill;\n              border-radius: 5px;\n              background-color: #20BEFF;\n              font-size: 100%;\n              font-family: Verdana\">\n    \nPredict whether or not a horse can survive based upon past medical conditions. There is an original dataset **horse-survival-dataset** I have also used for reference.**Outcome** is target variable.This is a **multi-class classification** challenge to predict horse survival using the provided features. We shall explore multi-class classification (not multi-label classification) as in competation description it is mention that submissions are evaluated on **micro-averaged F1-Score** between predicted and actual values. micro-averaged F1-Score is applicable for multi-class classification.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # visualization like pie plot\nimport seaborn as sns # visualization like scatter plot \npd.set_option('display.max_columns', 50) # display 50   columns by default\npd.set_option('display.max_rows', 50) # display 50 rows by default\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.478966Z","iopub.execute_input":"2023-10-01T15:00:04.479366Z","iopub.status.idle":"2023-10-01T15:00:04.490797Z","shell.execute_reply.started":"2023-10-01T15:00:04.479338Z","shell.execute_reply":"2023-10-01T15:00:04.489141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"original=pd.read_csv('/kaggle/input/horse-survival-dataset/horse.csv')\ntrain=pd.read_csv('/kaggle/input/playground-series-s3e22/train.csv')\ntest=pd.read_csv('/kaggle/input/playground-series-s3e22/test.csv')\nsubmission=pd.read_csv('/kaggle/input/playground-series-s3e22/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.493882Z","iopub.execute_input":"2023-10-01T15:00:04.49463Z","iopub.status.idle":"2023-10-01T15:00:04.540106Z","shell.execute_reply.started":"2023-10-01T15:00:04.494588Z","shell.execute_reply":"2023-10-01T15:00:04.53917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the id value as there is no importance for horse survival,it's just number\ntrain=train.drop('id',axis=1)\nid=test['id']\ntest=test.drop('id',axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.542086Z","iopub.execute_input":"2023-10-01T15:00:04.5428Z","iopub.status.idle":"2023-10-01T15:00:04.552275Z","shell.execute_reply.started":"2023-10-01T15:00:04.54276Z","shell.execute_reply":"2023-10-01T15:00:04.550476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first three rows of original dataset\noriginal.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.599125Z","iopub.execute_input":"2023-10-01T15:00:04.599901Z","iopub.status.idle":"2023-10-01T15:00:04.624752Z","shell.execute_reply.started":"2023-10-01T15:00:04.599856Z","shell.execute_reply":"2023-10-01T15:00:04.623606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first three rows of train dataset\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.649144Z","iopub.execute_input":"2023-10-01T15:00:04.649764Z","iopub.status.idle":"2023-10-01T15:00:04.674653Z","shell.execute_reply.started":"2023-10-01T15:00:04.649691Z","shell.execute_reply":"2023-10-01T15:00:04.673168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first three rows of test dataset\ntest.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.719216Z","iopub.execute_input":"2023-10-01T15:00:04.719593Z","iopub.status.idle":"2023-10-01T15:00:04.74718Z","shell.execute_reply.started":"2023-10-01T15:00:04.719564Z","shell.execute_reply":"2023-10-01T15:00:04.745554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first three rows of submission dataset\nsubmission.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.789034Z","iopub.execute_input":"2023-10-01T15:00:04.789407Z","iopub.status.idle":"2023-10-01T15:00:04.803671Z","shell.execute_reply.started":"2023-10-01T15:00:04.789378Z","shell.execute_reply":"2023-10-01T15:00:04.802744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring the Dataset","metadata":{}},{"cell_type":"code","source":"# Summary of Datasets\ndef summary(df):\n    data=pd.DataFrame(index=df.columns)\n    data['dtypes']=df.dtypes\n    data['count']=df.count()\n    data['#unique']=df.nunique()\n    data['#missing']=df.isna().sum()\n    data['missing%']=df.isna().sum()/len(df)*100\n    data=pd.concat([data,df.describe().T.drop('count',axis=1)],axis=1)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.813833Z","iopub.execute_input":"2023-10-01T15:00:04.814192Z","iopub.status.idle":"2023-10-01T15:00:04.821334Z","shell.execute_reply.started":"2023-10-01T15:00:04.814165Z","shell.execute_reply":"2023-10-01T15:00:04.820392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary of Training Dataset\nsummary(train).style.background_gradient(cmap='YlGnBu')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.848836Z","iopub.execute_input":"2023-10-01T15:00:04.849191Z","iopub.status.idle":"2023-10-01T15:00:04.934496Z","shell.execute_reply.started":"2023-10-01T15:00:04.849165Z","shell.execute_reply":"2023-10-01T15:00:04.933118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary of test Dataset\nsummary(test).style.background_gradient(cmap='YlOrBr')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:04.936489Z","iopub.execute_input":"2023-10-01T15:00:04.936864Z","iopub.status.idle":"2023-10-01T15:00:05.022556Z","shell.execute_reply.started":"2023-10-01T15:00:04.936833Z","shell.execute_reply":"2023-10-01T15:00:05.020793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"color: White; display: fill;\n              border-radius: 5px;\n              background-color: #20BEFF;\n              font-size: 100%;\n              font-family: Verdana\">\n    \n<b>Insight:</b>\n* We have numerical, categorical and object columns\n* Missing Values: The dataset contains a significant number of NA values, data imputation  will be required .\n* The column hosptial number can be treated as  a categorical variable because it represents the different hospitals.\n* Outcome: Target variable is  \"outcome\" variable. Possibilities include: lived, died, was euthanized.","metadata":{}},{"cell_type":"code","source":"# train dataset - displaying rows if any have duplicate rows\ntrain_duplicated_rows=train[train.duplicated()]\ntrain_duplicated_rows","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.024893Z","iopub.execute_input":"2023-10-01T15:00:05.025215Z","iopub.status.idle":"2023-10-01T15:00:05.047754Z","shell.execute_reply.started":"2023-10-01T15:00:05.02519Z","shell.execute_reply":"2023-10-01T15:00:05.046924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test dataset - displaying rows if any have duplicate rows\ntest_duplicated_rows=test[test.duplicated()]\ntest_duplicated_rows","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.049127Z","iopub.execute_input":"2023-10-01T15:00:05.049461Z","iopub.status.idle":"2023-10-01T15:00:05.072917Z","shell.execute_reply.started":"2023-10-01T15:00:05.049434Z","shell.execute_reply":"2023-10-01T15:00:05.071787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style = \"color: White; display: fill;\n              border-radius: 5px;\n              background-color:  #20BEFF;\n              font-size: 100%;\n              font-family: Verdana\">\n    \n* There is no duplicated rows in train & test dataset","metadata":{}},{"cell_type":"code","source":"#train dataset - displaying rows if any have null rows\ntrain[train.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.075278Z","iopub.execute_input":"2023-10-01T15:00:05.075753Z","iopub.status.idle":"2023-10-01T15:00:05.117965Z","shell.execute_reply.started":"2023-10-01T15:00:05.075687Z","shell.execute_reply":"2023-10-01T15:00:05.116666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test dataset - displaying rows if any have null rows\ntest[test.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.121421Z","iopub.execute_input":"2023-10-01T15:00:05.121906Z","iopub.status.idle":"2023-10-01T15:00:05.165718Z","shell.execute_reply.started":"2023-10-01T15:00:05.121874Z","shell.execute_reply":"2023-10-01T15:00:05.163594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset Attributes Description\ntrain.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.167885Z","iopub.execute_input":"2023-10-01T15:00:05.168199Z","iopub.status.idle":"2023-10-01T15:00:05.175347Z","shell.execute_reply.started":"2023-10-01T15:00:05.168174Z","shell.execute_reply":"2023-10-01T15:00:05.174233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #20BEFF; font-size:100%; text-align:left\">\n\n<h3 align=\"left\"><font color='#d79190'>💡 Dataset Attributes Description:</font></h3>\n\n<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\">\n    <thead>\n        <tr>\n            <th>Attribute</th>\n            <th>Description</th>\n            <th>Values</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>surgery?</td>\n            <td>Whether the horse had surgery</td>\n            <td>1 = Yes, 2 = No</td>\n        </tr>\n        <tr>\n            <td>Age</td>\n            <td>Age category of the horse</td>\n            <td>1 = Adult, 2 = Young (&lt; 6 months)</td>\n        </tr>\n        <tr>\n            <td>Hospital Number</td>\n            <td>Case number assigned to the horse</td>\n            <td>Numeric ID</td>\n        </tr>\n        <tr>\n            <td>rectal temperature</td>\n            <td>Temperature in degrees celsius</td>\n            <td>Linear</td>\n        </tr>\n        <tr>\n            <td>pulse</td>\n            <td>Heart rate in beats per minute</td>\n            <td>Linear</td>\n        </tr>\n        <tr>\n            <td>respiratory rate</td>\n            <td>Rate of respiration</td>\n            <td>Linear</td>\n        </tr>\n        <tr>\n            <td>temperature of extremities</td>\n            <td>Indication of peripheral circulation</td>\n            <td>1 = Normal, 2 = Warm, 3 = Cool, 4 = Cold</td>\n        </tr>\n        <tr>\n            <td>peripheral pulse</td>\n            <td>Subjective assessment of peripheral pulse</td>\n            <td>1 = Normal, 2 = Increased, 3 = Reduced, 4 = Absent</td>\n        </tr>\n        <tr>\n            <td>mucous membranes</td>\n            <td>Measurement of color of mucous membranes</td>\n            <td>1-6 as described in the given data</td>\n        </tr>\n        <tr>\n            <td>capillary refill time</td>\n            <td>Clinical judgment of capillary refill time</td>\n            <td>1 = &lt; 3 seconds, 2 = &gt;= 3 seconds</td>\n        </tr>\n        <tr>\n            <td>pain</td>\n            <td>Level of pain</td>\n            <td>1 = no pain, 2 = depressed, 3 = intermittent mild pain, 4 = intermittent severe pain, 5 = continuous severe pain </td>\n        </tr>\n        <tr>\n            <td>peristalsis</td>\n            <td>An indication of the activity in the horse's gut.</td>\n            <td>absent,hypomotile,hypermotile,normal </td>\n        </tr>\n        <tr>\n            <td>abdominal distention</td>\n            <td>an animal with abdominal</td>\n            <td>1 = none, 2 = slight, 3 = moderate, 4 = severe </td>\n        </tr>\n        <tr>\n            <td>nasogastric tube</td>\n            <td> any gas coming out of the tube</td>\n            <td>1 = none, 2 = slight, 3 = significant </td>\n        </tr>\n        <tr>\n            <td>nasogastric_reflux</td>\n            <td> the greater amount of reflux, the more likelihood that there is some serious</td>\n            <td>1 = none, 2 = > 1 liter, 3 = &lt; 1 liter </td>\n        </tr>\n        <tr>\n            <td>nasogastric_reflux_ph</td>\n            <td> scale is from 0 to 14 with 7 being neutral - normal values are in the 3 to 4 range</td>\n            <td>linear </td>\n        </tr>\n        <tr>\n            <td>rectal_exam_feces</td>\n            <td> indicates an obstruction</td>\n            <td>1 = normal, 2 = increased, 3 = decreased, 4 = absent  </td>\n        </tr>\n        <tr>\n            <td>abdomen</td>\n            <td> intestine size</td>\n            <td>1 = normal ,2 = other, 3 = large intestine, 4 = small intestine ,5 = distended </td>\n        </tr>\n        <tr>\n            <td>packed_cell_volume</td>\n            <td> red cells by volume in the blood - normal range is 30 to 50.</td>\n            <td>linear</td>\n        </tr>\n        <tr>\n            <td>total_protein</td>\n            <td> normal values lie in the 6-7.5 (gms/dL) range - the higher the value the greater the dehydration</td>\n            <td>linear</td>\n        </tr>  \n        <tr>\n            <td>abdominocentesis appearance</td>\n            <td>Appearance of fluid from abdominocentesis</td>\n            <td>1 = Clear, 2 = Cloudy, 3 = Serosanguinous</td>\n        </tr>\n        <tr>\n            <td>abdomcentesis total protein</td>\n            <td>Total protein from abdominocentesis</td>\n            <td>Linear (gms/dL)</td>\n        </tr>\n        <tr>\n            <td>outcome</td>\n            <td>Horse will survive ?</td>\n            <td>1 = Lived, 2 = Died, 3 = Euthanized</td>\n        </tr>\n        <tr>\n            <td>surgical lesion?</td>\n            <td>If the lesion was surgical</td>\n            <td>1 = Yes, 2 = No</td>\n        </tr>\n        <tr>\n            <td>type of lesion {lesion_1,lesion_2,lesion_3}</td>\n            <td>Type of lesion identified</td>\n            <td>Comprehensive description given (Multiple layers)</td>\n        </tr>\n        <tr>\n            <td>cp_data</td>\n            <td>Presence of pathology data for the case</td>\n            <td>1 = Yes, 2 = No</td>\n        </tr>\n    </tbody>\n</table>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"# Target variable distribution\nfig, ax = plt.subplots(1,2,figsize=(12,5))\n\n# ax[0] means first columns -- ax[0][0]\n# ax[1] means second columns -- ax[0][1]\n\nax[0].pie(x=train.outcome.value_counts(),\n          explode= [0.0, 0.2, 0.2],startangle= 45,\n          shadow = True,colors = ['#3377ff', '#66ffff','#809fff'],\n          autopct='%.1f%%',labels=train.outcome.value_counts().index,\n          textprops={'fontsize': 12, 'weight': 'bold'})\n# explode -- to make slice in pie graph and array value represent the distance between one slice to another\n# startangle -- to rotate slice\n# shadow -- to create shadow of graph i.e. back image\n\nsns.barplot(x=train.outcome.value_counts(),y=train.outcome.value_counts().index,ax=ax[1], palette='YlGnBu')\n\nplt.setp(ax[1].get_yticklabels(), fontweight=\"bold\") # get_yticklabels will fetch the yticklabels the setup will set again with bold changes\nplt.setp(ax[1].get_xticklabels(), fontweight=\"bold\") # get_yticklabels will fetch the xticklabels the setup will set again with bold changes\nax[1].set_xlabel('count',fontweight=\"bold\") # set x label\nax[1].set_ylabel('outcome',fontweight=\"bold\") # set x label\n\nax[1].spines['top'].set_visible(False) # it will remove the top boundry line\nax[1].spines['right'].set_visible(False) # it will remove the right boundry line\n\n# it will remove the x-axis tick and label\nax[1].tick_params(\n        axis='x',         \n        which='both',      \n        bottom=False,      \n        labelbottom=False\n    )\n\nval_count=train.outcome.value_counts()\nfor i,v in enumerate(val_count):\n    ax[1].text(v,i+0.1,str(v), fontdict={'fontsize':8,'fontweight':'bold'})\n# text --  is a function to add text to the graph\n# v, i+0.1 -- These are the x and y coordinates where the text will be placed. v is the value from the s1 array, and i+0.1 adds a small vertical offset to position the text slightly above the corresponding bar in the chart.\n# str(v) -- is the text \n\nfig.suptitle('Target Variable(Outcome) Distribution')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.176818Z","iopub.execute_input":"2023-10-01T15:00:05.177137Z","iopub.status.idle":"2023-10-01T15:00:05.653026Z","shell.execute_reply.started":"2023-10-01T15:00:05.177108Z","shell.execute_reply":"2023-10-01T15:00:05.651673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting categroical and continuous variables\n\n# unique value counts for each column\nunique_count=train.nunique()\n\n# unique count to distinguish between categroical and continuous\nmax_unique=10\n\ncat_cols=unique_count[unique_count<=max_unique].index.to_list()\ncont_cols=unique_count[unique_count>max_unique].index.to_list()\n\n#removing 'outcome'  from categorical variable as it is target variable\nif 'outcome' in cat_cols:\n    cat_cols.remove('outcome')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.655794Z","iopub.execute_input":"2023-10-01T15:00:05.657175Z","iopub.status.idle":"2023-10-01T15:00:05.67018Z","shell.execute_reply.started":"2023-10-01T15:00:05.657127Z","shell.execute_reply":"2023-10-01T15:00:05.669096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical Variable Distribution\ndef cat_distribution(df,columns,n_cols,hue):\n    '''\n    # Function to plot countplot for categorical varaible distribution\n    df: train dataset\n    columns: category variables\n    n_cols: num of cols\n    '''\n    n_rows=len(columns)//n_cols\n    fig,ax=plt.subplots(n_rows,n_cols,figsize=(18,4*n_rows))\n    ax=ax.flatten()  # Convert the ax array into a 1D array. means it converts ax 2-D array (6,3) into 1-D array to avoid issues.\n    for i,column in enumerate(columns):\n        sns.countplot(data=df,x=column,hue=hue,ax=ax[i],palette='viridis')\n        ax[i].set_title(f'{column} Counts',fontsize=12)\n        ax[i].tick_params(axis='x',rotation=10)\n        \n        #give the count on each bar graph\n        for p in ax[i].patches: # patches - contain the individual bar elements. Using patches we can access each element of bar graph\n            value = int(p.get_height())\n            ax[i].annotate(f'{value:.0f}', (p.get_x() + p.get_width() / 2, p.get_height()),\n                           ha='center', va='bottom', fontsize=9)\n        \n    plt.tight_layout()\n    plt.show()\n    \ncat_distribution(train,cat_cols,3,'outcome')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:05.671568Z","iopub.execute_input":"2023-10-01T15:00:05.672067Z","iopub.status.idle":"2023-10-01T15:00:10.952398Z","shell.execute_reply.started":"2023-10-01T15:00:05.67203Z","shell.execute_reply":"2023-10-01T15:00:10.951101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observations :\n* `lesion_2` Counts and `lesion_3` Counts appear to have similar distributions. When they are not 0, the horse has a high probability of not dying.","metadata":{}},{"cell_type":"code","source":"# Continuous Variable Distribution\nplt.figure(figsize=(14,len(cont_cols)*2.5))\n\nfor idx,column in enumerate(cont_cols):\n    plt.subplot(len(cont_cols),2,idx*2+1)\n    sns.histplot(data=train,x=column,hue='outcome',bins=30,kde=True,palette='Set1')\n    plt.title(f'{column} distribution for outcome')\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:10.954048Z","iopub.execute_input":"2023-10-01T15:00:10.954454Z","iopub.status.idle":"2023-10-01T15:00:16.925665Z","shell.execute_reply.started":"2023-10-01T15:00:10.954417Z","shell.execute_reply":"2023-10-01T15:00:16.924593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Continuous Variable Distribution with Outlier Check\ndf=pd.concat([train[cont_cols].assign(Source='train'),\n             test[cont_cols].assign(Source='test'),\n             original[cont_cols].assign(Source='original')],axis=0,ignore_index=True)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:16.931863Z","iopub.execute_input":"2023-10-01T15:00:16.932301Z","iopub.status.idle":"2023-10-01T15:00:16.958814Z","shell.execute_reply.started":"2023-10-01T15:00:16.932266Z","shell.execute_reply":"2023-10-01T15:00:16.957397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now plotting the plot\nfig,ax=plt.subplots(len(cont_cols), 4 ,figsize = (16, len(cont_cols) * 4.2))\n\nfor i,column in enumerate(cont_cols):\n    #plotting kde plot\n    sns.kdeplot(data=df[[column,'Source']],x=column,hue='Source',ax=ax[i,0])\n    ax[i,0].grid(visible=True, which = 'both', linestyle = '--', color='lightgrey', linewidth = 0.75);\n    ax[i,0].set(xlabel='',ylabel='')\n    ax[i,0].set_title(f'{column}',fontdict={'fontweight':'bold','fontsize':9})\n    \n    #plotting box plot to check outliers\n    #train dataset\n    sns.boxplot(data=df.loc[df.Source=='train',[column]],y=column,ax=ax[i,1],color='#037d97')\n    ax[i,1].set(xlabel='',ylabel='')\n    ax[i,1].set_title('train',fontdict={'fontweight':'bold','fontsize':9})\n    \n    #test dataset\n    sns.boxplot(data=df.loc[df.Source=='test',[column]],y=column,ax=ax[i,2],color='#E4591E')\n    ax[i,2].set(xlabel='',ylabel='')\n    ax[i,2].set_title('test',fontdict={'fontweight':'bold','fontsize':9})\n    \n    #original dataset\n    sns.boxplot(data=df.loc[df.Source=='original',[column]],y=column,ax=ax[i,3],color='#33ccff')\n    ax[i,3].set(xlabel='',ylabel='')\n    ax[i,3].set_title('original',fontdict={'fontweight':'bold','fontsize':9})\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:16.962836Z","iopub.execute_input":"2023-10-01T15:00:16.96317Z","iopub.status.idle":"2023-10-01T15:00:24.313277Z","shell.execute_reply.started":"2023-10-01T15:00:16.963143Z","shell.execute_reply":"2023-10-01T15:00:24.31229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Obserbations :\n* There are `outlier` in features and some oultliers shown in train and  test dataset buut not present in original dataset like `total_protein`","metadata":{}},{"cell_type":"markdown","source":"# Feature Encoding","metadata":{}},{"cell_type":"code","source":"cont_cols","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.314781Z","iopub.execute_input":"2023-10-01T15:00:24.315426Z","iopub.status.idle":"2023-10-01T15:00:24.328114Z","shell.execute_reply.started":"2023-10-01T15:00:24.315388Z","shell.execute_reply":"2023-10-01T15:00:24.326933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removed lesion_2 and lesion_3 from cat_cols as it's datatype is int and target feature is  outcome didn't add.\ncat_cols=['surgery','age','temp_of_extremities','peripheral_pulse','mucous_membrane',\n          'capillary_refill_time','pain','peristalsis','abdominal_distention','nasogastric_tube',\n          'nasogastric_reflux','rectal_exam_feces','abdomen','abdomo_appearance','surgical_lesion','cp_data']\n\n# Label encode categorical columns\nfrom sklearn.preprocessing import LabelEncoder\ndef feature_encoding (df,cat_cols):\n    label_encoders = {}\n    for column in cat_cols:\n        le=LabelEncoder() # as you label encoding handle one column at a time hence loop used to do label encoding for all features\n        df[column]=le.fit_transform(df[column])\n        label_encoders[column]=le\n    return df,label_encoders\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.329848Z","iopub.execute_input":"2023-10-01T15:00:24.33025Z","iopub.status.idle":"2023-10-01T15:00:24.342063Z","shell.execute_reply.started":"2023-10-01T15:00:24.330213Z","shell.execute_reply":"2023-10-01T15:00:24.341184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,label_encoders=feature_encoding(train,cat_cols)\ntest,label_encoders=feature_encoding(test,cat_cols)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.343194Z","iopub.execute_input":"2023-10-01T15:00:24.344102Z","iopub.status.idle":"2023-10-01T15:00:24.383011Z","shell.execute_reply.started":"2023-10-01T15:00:24.344064Z","shell.execute_reply":"2023-10-01T15:00:24.382179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoders","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.384128Z","iopub.execute_input":"2023-10-01T15:00:24.384851Z","iopub.status.idle":"2023-10-01T15:00:24.399621Z","shell.execute_reply.started":"2023-10-01T15:00:24.384812Z","shell.execute_reply":"2023-10-01T15:00:24.39833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.402747Z","iopub.execute_input":"2023-10-01T15:00:24.403083Z","iopub.status.idle":"2023-10-01T15:00:24.432782Z","shell.execute_reply.started":"2023-10-01T15:00:24.403055Z","shell.execute_reply":"2023-10-01T15:00:24.43145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.434895Z","iopub.execute_input":"2023-10-01T15:00:24.43534Z","iopub.status.idle":"2023-10-01T15:00:24.465507Z","shell.execute_reply.started":"2023-10-01T15:00:24.435299Z","shell.execute_reply":"2023-10-01T15:00:24.464193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Co - Relation","metadata":{}},{"cell_type":"code","source":"train_corr=train.copy()\ntrain_corr['outcome']=train_corr['outcome'].map({'lived':0,'died':1,'euthanized':2})\n\n# co - relation matrix table\ncorr=train_corr.corr()\ncorr","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.467458Z","iopub.execute_input":"2023-10-01T15:00:24.467901Z","iopub.status.idle":"2023-10-01T15:00:24.528212Z","shell.execute_reply.started":"2023-10-01T15:00:24.467861Z","shell.execute_reply":"2023-10-01T15:00:24.527088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heatmap (corr):\n    mask = np.zeros_like(corr) #create the same shape as the correlation matrix (corr) but is filled with zeros\n    mask[np.triu_indices_from(mask)] = True #This line fills the upper triangle of the mask array with True values. This is done to mask out the upper triangle of the correlation matrix in the heatmap\n    plt.figure(figsize=(14,10))\n    sns.heatmap(data=corr,annot=True,fmt='.2f',cmap='YlOrBr_r',mask=mask,annot_kws={\"size\": 6},linewidths=.5)#annot_kws={\"size\": 6} -- it will help to set the fontsize of annotation\n    plt.title('Train Dataset Co-Relation Matrix\\n',fontdict={'fontweight':'bold','fontsize':12})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.529718Z","iopub.execute_input":"2023-10-01T15:00:24.530039Z","iopub.status.idle":"2023-10-01T15:00:24.53701Z","shell.execute_reply.started":"2023-10-01T15:00:24.530012Z","shell.execute_reply":"2023-10-01T15:00:24.535599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heatmap(corr)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:24.538421Z","iopub.execute_input":"2023-10-01T15:00:24.538794Z","iopub.status.idle":"2023-10-01T15:00:26.207381Z","shell.execute_reply.started":"2023-10-01T15:00:24.538767Z","shell.execute_reply":"2023-10-01T15:00:26.206139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Obserbations\n* `hostpital_number` ,`abdomen`,`lesion_3` - these are less co-realted features with all the features.","metadata":{}},{"cell_type":"markdown","source":"# Imputation - Handling NULL Values","metadata":{}},{"cell_type":"code","source":"def imputation(df,cat_cols,cont_cols):\n    for cols in cat_cols:\n        df[cols]=df[cols].fillna(df[cols].mode()[0])\n    for cols in cont_cols:\n        df[cols]=df[cols].fillna(df[cols].median())\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.209033Z","iopub.execute_input":"2023-10-01T15:00:26.209364Z","iopub.status.idle":"2023-10-01T15:00:26.214657Z","shell.execute_reply.started":"2023-10-01T15:00:26.209335Z","shell.execute_reply":"2023-10-01T15:00:26.21365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removed lesion_2 and lesion_3 from cat_cols as it's datatype is int. \n# added hospital_number as it is a categoricaal type. \n# target feature is  outcome didn't add as it is not having any null value.\ncat_cols=['surgery','age','hospital_number','temp_of_extremities','peripheral_pulse','mucous_membrane',\n          'capillary_refill_time','pain','peristalsis','abdominal_distention','nasogastric_tube',\n          'nasogastric_reflux','rectal_exam_feces','abdomen','abdomo_appearance','surgical_lesion','cp_data']\n\n# adding lesion_2 and lesion_3\ncont_cals=['rectal_temp','pulse','respiratory_rate','nasogastric_reflux_ph',\n           'packed_cell_volume','total_protein','abdomo_protein','lesion_1','lesion_2','lesion_3']\n\ntrain=imputation(train,cat_cols,cont_cals)\ntest=imputation(test,cat_cols,cont_cals)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.216028Z","iopub.execute_input":"2023-10-01T15:00:26.21655Z","iopub.status.idle":"2023-10-01T15:00:26.263923Z","shell.execute_reply.started":"2023-10-01T15:00:26.21652Z","shell.execute_reply":"2023-10-01T15:00:26.262753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.267732Z","iopub.execute_input":"2023-10-01T15:00:26.268085Z","iopub.status.idle":"2023-10-01T15:00:26.277538Z","shell.execute_reply.started":"2023-10-01T15:00:26.268057Z","shell.execute_reply":"2023-10-01T15:00:26.276713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.279122Z","iopub.execute_input":"2023-10-01T15:00:26.279812Z","iopub.status.idle":"2023-10-01T15:00:26.295425Z","shell.execute_reply.started":"2023-10-01T15:00:26.279771Z","shell.execute_reply":"2023-10-01T15:00:26.29464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; border:#b2d790 solid; padding: 15px; background-color: #20BEFF; font-size:100%; text-align:left\">\n<h3 align=\"left\"><font color='#d79190'>💡 Multi-class vs Multi-label</font></h3>\nThe difference between multi-label classification and multi-class classification is as follows:\n<br><br>\n<b>Multi-label Classification:</b><br> Multi-label classification deals with scenarios where each data instance can be assigned to multiple labels or classes. This means that a single data point can belong to multiple classes simultaneously. For example, in image classification, an image may have multiple objects or attributes, and we want to predict all of them. This problem is tackled using multi-label classification.\n<br><br>\n<b>Multi-class Classification:</b><br> Multi-class classification, on the other hand, deals with scenarios where each data instance can be assigned to only one class out of several possible classes. Each data point is assigned to a single class exclusively.For example, classifying an email into categories like \"spam,\" \"ham,\" or \"promotions\" is a multi-class classification problem because each email belongs to one of these mutually exclusive categories This problem is tackled using multi-class classification.\n<br><br>\n<br>Algorithms like XGBoost, LightGBM, and CatBoost are powerful ensemble methods that can be effective for multi-label as well as multi-class classification tasks.  \n<br><br>    \nIn the given problem, it is a multi-class problem. \n\n<br><br>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"![](https://editor.analyticsvidhya.com/uploads/62036WhatsApp%20Image%202021-07-19%20at%2014.31.27.jpeg)\n\nImage source: Analytics Vidhya","metadata":{}},{"cell_type":"code","source":"#model\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n#model selection\nfrom sklearn.model_selection import KFold\n#metrics\nfrom sklearn.metrics import f1_score,confusion_matrix\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.296548Z","iopub.execute_input":"2023-10-01T15:00:26.29703Z","iopub.status.idle":"2023-10-01T15:00:26.306938Z","shell.execute_reply.started":"2023-10-01T15:00:26.297004Z","shell.execute_reply":"2023-10-01T15:00:26.305999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# spilitting the input feature and target variable\ntrain['outcome']=train['outcome'].map({'lived':0,'died':1,'euthanized':2})\nX=train.drop('outcome',axis=1)\ny=train['outcome']","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.308076Z","iopub.execute_input":"2023-10-01T15:00:26.308538Z","iopub.status.idle":"2023-10-01T15:00:26.326798Z","shell.execute_reply.started":"2023-10-01T15:00:26.308512Z","shell.execute_reply":"2023-10-01T15:00:26.325424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cv_scores = list()\nlgbm_cv_scores = list()\ncat_cv_scores = list()\n\nkf=KFold(n_splits=5,shuffle=True,random_state=42)\n\n\nfor idx,(train_idx,test_idx) in enumerate(kf.split(X,y)):\n    X_train,X_test=X.iloc[train_idx],X.iloc[test_idx]\n    y_train,y_test=y.iloc[train_idx],y.iloc[test_idx]\n    \n    \n    print('---------------------------------------------------------------')\n    \n# Modified hyperparameters\n    \n    #XGBClassifier\n    xgb_md = XGBClassifier(n_estimators=1000, \n                           max_depth=3, \n                           early_stopping_rounds=50,\n                           learning_rate=0.55,\n                           min_child_weight=2,\n                           colsample_bytree=0.9,\n                           objective='multi:softmax',\n                           eval_metric='merror',\n                           random_state=1)\n    xgb_md.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=10000)\n    xgb_pred=xgb_md.predict(X_test)\n    xgb_f1 = f1_score(y_test, xgb_pred, average = 'micro')\n    print('Fold', idx+1, '==> XGBoost oof F1 score is ==>', xgb_f1)\n    xgb_cv_scores.append(xgb_f1)\n    \n    \n    #LightGBM\n    lgbm_md = LGBMClassifier(n_estimators=100, random_state=42)\n    lgbm_md.fit(X_train, y_train)\n    lgbm_pred = lgbm_md.predict(X_test)   \n    lgbm_f1 = f1_score(y_test, lgbm_pred, average = 'micro') \n    print('Fold', idx+1, '==> LightGBM oof F1 score is ==>', lgbm_f1)\n    lgbm_cv_scores.append(lgbm_f1)\n    \n    \n    #CatBoost\n    cat_md = CatBoostClassifier(loss_function = 'MultiClass',\n                                iterations = 500,\n                                learning_rate = 0.01,\n                                depth = 7,\n                                random_strength = 0.5,\n                                bagging_temperature = 0.7,\n                                border_count = 30,\n                                l2_leaf_reg = 5,\n                                verbose = False, \n                                task_type = 'CPU')\n    cat_md.fit(X_train, y_train)\n    cat_pred = cat_md.predict(X_test)   \n    cat_f1 = f1_score(y_test, cat_pred, average = 'micro')\n    print('Fold', idx+1, '==> CatBoost oof F1 score is ==>', cat_f1)\n    cat_cv_scores.append(cat_f1)\n    \n    \nprint('---------------------------------------------------------------')\nprint('Average Accuracy of XGBoost model is:', np.mean(xgb_cv_scores))\nprint('Average Accuracy of LGBM model is:', np.mean(lgbm_cv_scores))\nprint('Average Accuracy of Catboost model is:', np.mean(cat_cv_scores))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:26.328503Z","iopub.execute_input":"2023-10-01T15:00:26.329154Z","iopub.status.idle":"2023-10-01T15:00:42.981549Z","shell.execute_reply.started":"2023-10-01T15:00:26.329119Z","shell.execute_reply":"2023-10-01T15:00:42.98034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importances","metadata":{}},{"cell_type":"code","source":"def feature_importances(model):\n    feature_importance=pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)\n    return feature_importance","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:42.983274Z","iopub.execute_input":"2023-10-01T15:00:42.983684Z","iopub.status.idle":"2023-10-01T15:00:42.991076Z","shell.execute_reply.started":"2023-10-01T15:00:42.983646Z","shell.execute_reply":"2023-10-01T15:00:42.990015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graph(feature_importance,model_name):\n    plt.figure(figsize=(8,5))\n    a=sns.barplot(x=feature_importance,y=feature_importance.index,palette='viridis')\n    plt.xticks([])\n    for j in ['right', 'top', 'bottom']:\n        a.spines[j].set_visible(False)\n    plt.title(f\"{model_name} feature importances\\n\")\n    plt.show()\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:42.99246Z","iopub.execute_input":"2023-10-01T15:00:42.99279Z","iopub.status.idle":"2023-10-01T15:00:43.015921Z","shell.execute_reply.started":"2023-10-01T15:00:42.992762Z","shell.execute_reply":"2023-10-01T15:00:43.014494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_graph(feature_importances(xgb_md),'xgb')\nplot_graph(feature_importances(lgbm_md),'lgbm')\nplot_graph(feature_importances(cat_md),'cat')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:43.017424Z","iopub.execute_input":"2023-10-01T15:00:43.017906Z","iopub.status.idle":"2023-10-01T15:00:44.234882Z","shell.execute_reply.started":"2023-10-01T15:00:43.017866Z","shell.execute_reply":"2023-10-01T15:00:44.233607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Submission","metadata":{}},{"cell_type":"code","source":"#Pred\nxgb_md.fit(X,y,eval_set=[(X_test, y_test)])\nxgb_pred_test = xgb_md.predict(test)\n#Pred\nlgbm_md.fit(X,y)\nlgbm_pred_test = lgbm_md.predict(test)\n#Pred\nlgbm_md.fit(X,y)\ncat_pred_test = cat_md.predict(test)\ncat_pred_test=cat_pred_test.ravel() #convert 2-D into 1-D","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:44.236668Z","iopub.execute_input":"2023-10-01T15:00:44.237074Z","iopub.status.idle":"2023-10-01T15:00:49.871921Z","shell.execute_reply.started":"2023-10-01T15:00:44.237043Z","shell.execute_reply":"2023-10-01T15:00:49.870874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_submission(final_predictions,model_name):\n    submission = pd.DataFrame({'id': id , 'outcome': final_predictions})\n    submission['outcome'] = submission['outcome'].map({0:'lived',1:'died',2:'euthanized'})\n    submission.to_csv(f'{model_name}_submission.csv',index=False)\n    print(f'Result:{model_name}_submission is saved!')\n\n    return submission","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:49.873444Z","iopub.execute_input":"2023-10-01T15:00:49.873972Z","iopub.status.idle":"2023-10-01T15:00:49.882668Z","shell.execute_reply.started":"2023-10-01T15:00:49.87393Z","shell.execute_reply":"2023-10-01T15:00:49.881582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_xgb = get_submission(lgbm_pred_test,'xgb')\nsub_lgbm = get_submission(xgb_pred_test,'lgbm')\nsub_cat = get_submission(cat_pred_test,'catboost')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:49.883962Z","iopub.execute_input":"2023-10-01T15:00:49.884234Z","iopub.status.idle":"2023-10-01T15:00:49.906553Z","shell.execute_reply.started":"2023-10-01T15:00:49.88421Z","shell.execute_reply":"2023-10-01T15:00:49.905678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get final prediction\npreds = [sub_xgb,sub_lgbm,sub_cat]\nmerged_df = pd.concat(preds)\nfinal_predictions = merged_df.groupby('id')['outcome'].apply(lambda x: x.mode().iloc[0]).reset_index()\nfinal_predictions.to_csv('final_preds.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T15:00:49.907658Z","iopub.execute_input":"2023-10-01T15:00:49.908546Z","iopub.status.idle":"2023-10-01T15:00:50.04319Z","shell.execute_reply.started":"2023-10-01T15:00:49.908516Z","shell.execute_reply":"2023-10-01T15:00:50.04191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius:10px; border:#b2d790 solid; padding: 15px; background-color:  #20BEFF; font-size:100%; text-align:left\">\n<h3 align=\"left\"><font color='#d79190'>💡 Multiclass Classification Evaluation Method - Micro Average F1 Score: A Closer Look</font></h3>\n\n* Micro Average F1 Score: In multiclass classification problems, the Micro Average F1 Score provides a comprehensive measure of a model's performance, especially when there's class imbalance. It considers every instance or prediction equally, regardless of the class. Specifically, it aggregates the contributions of all classes to compute the average metric.\n\n* Example: Consider we have a multiclass classification problem where we predict animal types: Cats, Dogs, and Birds. Let's say the total number of instances are 1000, where:\nTrue Cats: 800, Predicted Cats: 750\nTrue Dogs: 100, Predicted Dogs: 125\nTrue Birds: 100, Predicted Birds: 125\nUsing these numbers, we'd first calculate the overall true positives, false positives, and false negatives and then compute the F1 score. The micro-averaged F1 score would be a measure based on all 1000 instances.\n\n* Class Imbalance Concerns: When datasets have an imbalanced class distribution, performance metrics can be skewed. In such cases, the Micro Average F1 Score proves valuable as it takes into account true positives, false positives, and false negatives from all classes to provide a holistic measure.\n\n* Difference from Macro Average: While both are popular evaluation metrics for multiclass classification, they have distinct applications. Micro averages the performance on individual instances, making it less sensitive to class imbalance. On the other hand, Macro average treats each class equally, averaging the performance on a per-class basis. This means, if performance on a minority class is poor, it will reflect heavily on the Macro averaged result.\n\n* Practical Implications: In real-world applications with imbalanced datasets, relying solely on metrics like accuracy or macro-averaged scores might be misleading. Micro Average F1 Score serves as a more consistent measure, ensuring that the model's performance is evaluated holistically across all instances and classes.\n\n* Final Note: It's essential to choose the right evaluation metric based on the nature of the problem and the dataset at hand. Micro Average F1 Score stands out as a robust metric for datasets with varying class distributions, ensuring that every prediction, irrespective of its class, contributes equally to the final score.","metadata":{}},{"cell_type":"markdown","source":"# References\n* https://www.kaggle.com/code/kimtaehun/eda-and-baseline-with-multiple-models\n* https://www.kaggle.com/code/ravi20076/playgrounds3e22-eda-baseline\n* https://www.kaggle.com/code/yaaangzhou/playground-s3-e22-eda-modeling#Predict-Health-Outcomes-of-Horses\n\nThank You :)","metadata":{}}]}